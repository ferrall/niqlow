/** Read this to find out how to solve the dynamic program using different methods.
<a href="#auto"><span class="skip"><abbr title=" Skip down to items defined in Methods.ox">&nbsp;&#8681;&nbsp;</abbr></span></a>

@sortkey A

<OL class="body">

<li>Overview</li>

Once your code has called <code>CreateSpaces()</code> your DP model is set up and ready to be solved.  To do this, apply a <em>solution method</em> to the model, which is an object derived from the `Method` class. You can apply more than one method to your problem, although some methods only work with some kinds of models.</p>

Every Method has a <code>Solve()</code> function that applies the method to the DP problem.  Solution methods work at the highest level of the DP environment.  That is, if your DP environment involves multiple problems (because it includes fixed and random effects), the solution method will call methods to handle each specific DP problem. (It is possible to specify that only one problem be solved, and this is used to efficiently parallelize the solution of many DP problems over a cluster.)</p>

The most flexible way to use a solution method is to create a new object of the method and then call its <code>Solve</code> routine in any place of the code.  This approach is necessary when using a <em>nested algorithm</em> in which the DP solution is embedded inside some other iteration (such as estimating parameters of the model).  Some of the solution methods have a simpler version in which the code calls a function that creates the method for the user, applies it solve routine and then deletes the method.  Both possibilities are shown here:

<DT>Example: Solve <code>MyModel</code> with brute force value function iteration:</DT>
<DD>Option 1 (more general)
<pre>
&vellip;
CreateSpaces();
vmax = new ValueIteration();
vmax.Volume = LOUD;               //V(&theta;) printed when computed
vmax -&gt; Solve();
&vellip;
</pre></DD>
<DD>Option 2 (simple)
<pre>
&vellip;
CreateSpaces();
VISolve();
&vellip;
</pre></DD>

<DT>What happens with a call to <code>Solve()</code></DT>
<DD><table class="tree">
<tr>
<td class="line">&nbsp;</td>
<td class="line"><div class="vline"><div class="hline">&nbsp;</div></div></td>
<td style="height:1px; width:auto;" colspan="7" class="fffix">
<table class="labelwrapper">
   <tbody><tr><td class="label">`ValueIteration::Solve`</td></tr>
   <tr class="bottom"><td class="line"><div class="vline">&nbsp;</div></td></tr>
</tbody></table>
</td>
<td class="text">Loop over fixed effect variables in &gamma;, solve each problem by calling the `RandomSolve`() task.<br>Reuse the solution storage space for each fixed effect to conserve on memory.</td>
</tr>
<tr>
<td class="line">&nbsp;</td>
<td class="line"><div class="vline">&nbsp;</div></td>
<td class="line">&nbsp;</td>
<td class="line"><div class="vline last"><div class="hline">&nbsp;</div></div></td>
<td style="height:1px; width:auto;" colspan="5" class="fffix">
<table class="labelwrapper">
   <tbody><tr><td class="label">`RandomSolve`</td></tr>
   <tr class="bottom"><td class="line"><div class="vline">&nbsp;</div></td></tr>
</tbody></table>
</td>
<td class="text">For the current fixed group, loop over random effect variables in &gamma;. Solve each problem by calling `GSolve`().<br> Reuse value iteration space but store choice probabilities for all random effect groups.</td></tr>
<tr>
<td class="line">&nbsp;</td>
<td class="line"><div class="vline">&nbsp;</div></td>
<td class="line">&nbsp;</td>
<td class="line">&nbsp;</td>
<td class="line"><div class="vline last"><div class="hline">&nbsp;</div></div></td>
<td style="height:1px; width:auto;" colspan="4" class="fffix">
<table class="labelwrapper">
   <tbody><tr><td class="label">`GSolve`</td></tr>
   <tr class="bottom"><td class="line"><div class="vline">&nbsp;</div></td></tr>
</tbody></table>
</td>
<td class="text">Given the fully specified fixed vector &gamma; (a group), which defines an element of the group space, solve the DP problem. This is where the state space $\Theta$ is traversed applying Bellman's equation at each point.</td>
</tr>
<tr>
<td class="line">&nbsp;</td><td class="line"><div class="vline">&nbsp;</div></td>
<td class="line">&nbsp;</td><td class="line">&nbsp;</td><td class="line">&nbsp;</td>
<td class="line"><div class="vline last"><div class="hline">&nbsp;</div></div></td>
<td style="height:1px; width:auto;" colspan="3" class="fffix">
<table class="labelwrapper">
   <tbody><tr><td class="label">Inner loop of GSolve</td></tr>
   <tr class="bottom"><td class="line">&nbsp;</td></tr>
</tbody></table>
</td>
<!--    0. `EndogUtil`         initialize over endogenous states &theta;-->
<td class="text"><pre>
    1. `GSolve::Run`            loop over bellman iterations (or other task)
    2. `GSolve::Update`         check convergence/work backwards (return to 1 until finished.)</pre>
</td></tr></table></DD>

<DT>Solution Methods are Categorized As Follows (also click on <a href="hierarchy.html">Class hierarchy</a> at the top of any page in the DDP folder (like this page).</DT>

<dd><pre>
Method
    ValueIteration
    HotzMiller
    SolveAsSystem
    ReservationValues
    </pre></dd>
Within these top level categories there are some derived classes for particular algorithms.

<li>Value Function Iteration Methods</LI>

Value function iteration applies Bellman's EMax operator, $V(\theta)\ =\ \max U() + \delta EV(\theta')</code> $ to solve for the value function and optimal choice probabilities.

<OL class="chapter">
<LI>Brute Force Iteration</LI>
<DT>`ValueIteration` performs <q>brute force</q> Bellman Equation iteration.</DT>
<DD>Example<pre>
CreateSpaces();
&vellip;
decl vmax = new ValueIteration();
vmax -&gt; Solve();
</pre></DD>

<LI>Keane-Wolpin Approximation</LI>
<DT>`KeaneWolpin` is derived from `ValueIteration` and approximates the solution to the value function at a subsample of the state space.</DT>
<DD>Example<pre>
CreateSpaces();
&vellip;
SubSampleStates(0.4);
decl kw = new KeaneWolpin();
kw -&gt; Solve();
</pre></DD>
</OL>

<LI>HotzMiller:  Conditional Choice Probability Methods</LI>

CCP methods use estimates of conditional choice probabilities and inverts a function of them to compute (differences in) the value function without Bellman Iteration.  They rely on the `CCP` task which smooths data on observed choices to produce an estimate of $P^\star(\alpha;\theta)$ that does require a solution to $V(\theta)$.</p>

<OL class="chapter">
<LI>Hotz-Miller</LI>
<DT>`HotzMiller` is the basic CCP method that inverts a function of the estimated CCPs to compute (differences in) the value function without Bellman Iteration.  </DT>
<DD>Example<pre>
CreateSpaces();
&vellip;
HM = new HotzMiller(data);
</pre></DD>


<LI>Aguirregabiria and Mira</LI>
<DT>`AguirregabiriaMira` is derived from `HotzMiller`.  It iterates on the Hotz-Miller inverstion to gain efficiency in estimates</DT>
</OL>

<LI>Reservation values </LI>

`ReservationValues` is a method for solving for cut-off values in a one-dimensional continuous state variable.

<OL class="chapter">
<LI>The continuous vector $\zeta$ must contain only one variable: $\zeta = (z)$, not the typical vector of action-specific shocks. </LI>
<LI>The action vector $\alpha$ must contain only one action: $\alpha = (a)$.  This does not mean a binary choice: <code>a</code> can take on any number of values.  To enforce this, <code>MyModel</code> must be derived from the `OneDimensionalChoice` class.</LI>
<LI>The value of actions must satisfy the reservation property:</LI>
<DD><img src="zstar.png"/></DD>
</OL>


<LI>Hybrid Solution Methods</LI>
<DT>Some methods for solving DDP rely not on non-linear optimization and root-finding.  These methods combine <span class="n">DDP</span> and <span class="n">FiveO</span>.  </DT>
<DT>They are categorized as <a href="..\Hybrids\default.html">Hybrid Methods</a> and discussed separately.</DT>

</OL>
</OL>
@author &copy; 2011-2019 <a href="http://econ.queensu.ca/~ferrall">Christopher Ferrall</a></dd>
<a name="auto"><hr><h1>Documentation of  Items Defined in Methods.ox <a href="#"><span class="skip"><abbr title=" Back to top">&nbsp;&#8679;&nbsp;</abbr></span></a></h1></a>

**/
