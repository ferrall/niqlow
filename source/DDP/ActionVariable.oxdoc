/**Elements of the action vector <code>&alpha;</code>.

@sortkey BBB

<a href="#auto">Skip down to documentation of items defined in ActionVariable.ox</a><p>
<OL class="contents">Contents
<LI><a href="#Basics">Basics</a></LI>
<LI><a href="#AC">Actual and Current Values</a></LI>
<LI><a href="#PF">Possible and Feasible Actions</a></LI>
</OL>

<OL class="body">
<a name="Basics"><LI>Basics</LI></a>

<DT>Action vector <code>&alpha;</code> :</DT>
    <DD>The vector of discrete actions.  A generic element of <code>&alpha;</code> is denoted <var>a</var>.  An action variable takes on <code>a.N</code> different values.</DD>
    <DD>The action vector includes <code>&alpha;.N</code> variables, denoted a<sub>0</sub> through a<sub>(&alpha;.N)&oline;</sub>.</DD>
    <DD>Action variables are represented as an `ActionVariable` and are added to <code>MyModel</code> and to <code>&alpha;</code> using `DP::Actions`(). </DD>
    <DD>Calls to <code>Actions()</code> and other model-building routines is part of <code>MyCode</code>.</DD>

<DT>Possible Actions: <code>&Alpha;</code></DT>
<DD>In the basic definition of a DDP model, <code>&Alpha;</code> is defined as the set of possible actions. In <span class="n">DDP</span> the set of actions is built up by adding action variables to <code>&alpha;</code>.  So <code>&Alpha;</code> emerges from the properties of the variables added to <code>&alpha;</code>.</DD>
<DD class="example">Possible Actions is the matrix of all possible action vectors: <details class="aside"><summary>Terminology:</summary>The word <em>possible</em> is used instead of <em>feasible</em>, because this notion of <code>&Alpha;</code> is constructed mechanically from properties of the actions.  It has nothing to do with the interpretation of the actions.  Feasible actions are defined below. An <em>action</em> refers to a particular value of the action vector <code>&alpha;</code>, which in turn is  a row of <code>&Alpha;</code>. An action variable refers to a column of <code>&Alpha;</code>, but note that values of an action variable are repeated within the column.</details>
<pre>
    &Alpha; &equiv; &times;<sub>j=0 &hellip; (&alpha;.N)&oline; </sub> { 0, 1, &hellip;, (a<sub>j</sub>.N)&oline; }</pre>
    DDP constructs &Alpha; when <code>MyCode</code> calls <code>CreateSpaces()</code>.</DD>
<DT>Alternative Notation</DT>
<DD>Discrete choice is described in two ways other than the one above used in <span class="n">DDP</span>.</DD>
<DD>For example, suppose there are two action variables and 6 total action vectors:
 <pre>&alpha; = (a<sub>0</sub>,a<sub>1</sub>)
 a<sub>0</sub>.N=3
 a<sub>1</sub>.N=2
 &alpha;.D=6</pre></DD>
 <DD>Some papers would treat this as a <em>single action</em> with six values.</DD>
<DD>And/or papers may define a vector of 6 indicator variables to denote which choice was made: <var>d<sub>i</sub>=I{a=i}</var>.</DD>
<DD>The three different approaches to coding discrete choices are illustrate in this table:<pre>
         DDP Approach       | Single Action |    Indicator Vectors
         a0         a1      |       a       |    d0  d1  d2  d3  d4  d5
      ----------------------+---------------+----------------------------
         0          0       |       0       |    1   0   0   0   0   0
         1          0       |       1       |    0   1   0   0   0   0
         2          0       |       2       |    0   0   1   0   0   0
         0          1       |       3       |    0   0   0   1   0   0
         1          1       |       4       |    0   0   0   0   1   0
         2          1       |       5       |    0   0   0   0   0   1</pre></DD>
<DD>One reason to use an action vector like <code>&alpha;</code> is that each variable can be interpreted as a dimension of choice.  There is no obvious interpretation of <q>a=3</q> in the table, and the interpretation would change with the dimensions of the action variables. This approach would force <code>MyModel</code> to decode into an action vector to make their code look like a mathematical model. Another reason: the action vector approach makes it natural to impose feasibility conditions on the choice set, as discussed below.</dd>
<DD>The use of indicator vectors makes it possible to write any utility as a sum: <var>U = &sum;<sub>k</sub> d<sub>k</sub>u<sub>k</sub></var>. But as with the single action approach the interpretation is not obvious and <var>U()</var> will in no way resemble usual mathematical notation for an objective.</DD>

<DT>Explanation:</DT>
<DD>Action variables objects must be <code>static</code> data members of <code>MyModel</code>. </DD>
<DD>Action variables objects must be created between the calls to <code>Initialize()</code> and <code>CreateSpaces()</code>.</DD>
<DD>It is possible to combine the creation and adding of the action variable as in <code>Actions(a=new ActionVariable("choice",2))</code>.  Multiple actions can be added with a single call to actions, and `DP::Actions`() can be called several times.</DD>

<LI>Actual and Current Values of an Action Variable</LI>

Usually an action variable can be an object of the base `ActionVariable` class.  The user only needs to define a derived class.

<DT>Current Value</DT>
        <DD><span class="n">DDP</span> requires <code>MyModel</code> to handle/process the full matrix of feasible actions in utility and transitions.
        <DD>For this reason, <code>MyModel</code> will rarely if ever access the current value of an action, <code>a.v</code>.  </DD>
        <DD>The vector of values of an action variable that corresponds to feasible &alpha;s is returned by <code>`Bellman::aa`(a).</code></DD>
<DT>
<DT>Actual Value</DT>
<DD>Optionally, the user can create a class derived from `ActionVariable` and supply a `Discrete::Update` function with it.</DD>
<DD>This allows the user to associate a meaningful value for the numbers 0 to N&oline;, stored as <code>a.`Discrete::actual`</code>.</DD>
<DD><span class="n">DDP</span> updates an action each time the problem is resolved, so actual values can depend on `Parameter` values.</DD>
<DD>`Bellman::aa`(a) will indeed return the actual values of <code>a</code> that correspond to each feasible action vector &alpha;.</DD>
<DD>The default virtual `Discrete::Update`() simply sets actual to the vector &lt; 0 : N-1 &gt;.</DD>

<DT>Example of Custom <code>Update()</code></DT>
<DD>Unless you want to provide actual values for an action you do not need to create a derived class.
<DD class="example">Let <var>a</var> denote a discrete choice of hours to work each week.  The maximum number of hours, <var>H</var>, depends on a parameter which can differ across individuals but is constant across the state space. 
<details><summary>Actual Hours action variable</summary><pre>
struct Hours : ActionVariable {
        decl H;
        Hours(const N,const H);
        Update();
        }
Hours::Hours(const N,const H) {
        this.H = H;
        ActionVariable("h",N);
        }
Hours::Update() {
        actual = AV(H)* (vals / N);
        }
&hellip;
MyModel::MaxH() { return CV(hasch) ? 30 : 50; }
&hellip;
MyModel::Initialize() {
   hellip;
   GroupVariables(hasch = new FixedEffect("",2));
   Actions(h = new Hours(5,MyModel::MaxH));
   hellip;
   } 
MyModel::Utility() {
        return CV(wage)*aa(h);
        }</pre></details>
The code segment allows the maximum hour to be 30 if the person has a (young) child, otherwise 50 hours.  And then lets each type choose 5 different levels of hours between 0 and their max hours.  Utility will be total earnings.
</DD>

<LI>Possible and Feasible Actions</LI>
<DT>Possible Actions.</DT>
<DD><var>A</var> is defined as the set of possible actions, built up by adding action variables to &alpha;:<pre>
<b>Possible Actions</b> is the matrix of all possible action values:
    A &equiv; &times;<sub>j=0 &hellip; &alpha;.N&oline; </sub> { 0, 1, &hellip;, a<sub>j</sub>.N&oline; }</pre>
    An action vector &alpha; is a <em>row</em> of the matrix A.    </DD>
<DT>The position property</DT>
<DD class="example">An action variable is a column of <var>A</var>.  Its position is the property <code>a.pos</code>. </DD>
<DT>Feasible Actions</DT>
<DD><em>Feasibility</em> is a property <code>MyModel</code> imposes on &alpha;. The model may say that some logically possible actions cannot be chosen because they do not make sense given the interpretation of &alpha;.  Or some actions are ruled infeasible for convenience to avoid calculations that are relatively unimportant. We write feasibility as a property of the state:
<pre>The <b>feasible actions</b> at &theta; is a matrix property:
     &forall; &theta; &in; <b><b>&Theta;</b></b>, &theta;.A &sube; A.</pre></DD>
<DT>`Bellman::FeasibleActions`(): by default all possible actions are feasible</DT>
<DD>If <code>MyModel</code> does not say otherwise, &theta;.A &equiv; A for all endogenous states.</DD>
<DD>This behaviour is produced by including a built in method, <code>Bellman::FeasibleActions()</code>, which is a virtual method, meaning that <code>MyModel</code> can replace it with its own version.
<DT>Overriding the default: <code>MyModel::FeasibleActions()</code></DT>
<DD>If the user supplies a replacement for <code>FeasibleActions()</code> it must take a single argument <code>A</code>, which is the possible matrix <var>A</var>, each row is an action vector &alpha; and each column is an action variable a that was added to the model.
<DD class="example"><code>MyModel::</code>must return a column vector which indicates that &alpha; is feasible or not.
<pre>FeasibleActions() = a A.N vector containing
      I{A.i&in;&theta;.A}, i = 0 &hellip; A.N&oline;.</pre></DD>
<DD>This requirement explains that the default method returns a vector of 1s equal in size to the rows of <var>A</var>.
<DT>The A List</DT>
<DD>`DP::CreateSpaces` constructs the possible matrix A, actually stored as the first element of a list (<code>OxArray</code>):  <var>A</var> &harr; <code>A[0]</code>. It then calls <code>FeasibleActions(A)</code> for each reachable state &theta;.  Every time a different value is returned a new matrix is added to the A list.  The index into the list is then stored as  <code>Aind</code> &harr;  &theta;.j.</DD>
<DD>The user's feasible action method should determine feasibility using the action variables stored in the derived DP model.  So if <code>a</code> contains an <code>ActionVariable</code> its value are available directly as <code>A[Aind][][a.pos]</code> or with <code>aa(a)</code>.</DD>
<DD>In short, &theta;.A &harr; <code>A[Aind]</code>. If <code>MyModel</code> does not specify feasible actions, then <code>Aind = &theta;.j = 0</code> for all states.</DD>
<DT>The A list contains the <em>actual</em> values not the <em>current</em> values.</DT>
<DD>If the user provides an `Discrete::Update`() for a derived class of action variable, then <code>A[Aind]</code> is the matrix of actual values.</DD>
<DD>Since the default is that actual values equal current values (<code>a.actual[a.v] = a.v</code>), then <code>A[Aind]</code> is always possible to use.</DD>
<DD>The uncoded list of matrices is available as `DP::ActionMatrix`.</DD>
<DT>Example </DT><DD class="example">
Suppose the only constraint on actions is that an action <var>a=0</var> is not feasible when a state variable <var>q=2</var>.  (For example, going to high school is not feasible if the person already has a high school degree.<pre>
FeasibleActions(const A) {    return CV(x)==2 ? aa(a).!=0 : ones(rows(A),1) ;    }
</pre>
Code this way it does not matter whether more variables are added to the model and it does not matter what order the code adds the actions to &alpha;.  <code>FeasibleActions</code> is robust to those details.
</DD>
</OL>

<hr><a name="auto"><h1>Documentation of  Items Defined in ActionVariable.ox</h1></a>

**/
