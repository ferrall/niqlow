/** Describes how the user constructs Utility, Reachable States and other aspects of the DP model's state space &Theta;.
<a href="#auto"><span class="skip"><abbr title=" Skip down to items defined in Bellman.ox">&nbsp;&#8681;&nbsp;</abbr></span></a>

@sortkey C

<OL class="body">

<li>Overview</li>

`Bellman` is derived from the `DP` class which contains <em>static</em> elements of the code.  These <a href="#static">components are described in more detail below.</a> Classes based on Bellman capture different specifications of the model, especially in terms of the <em>iid continuous state vector</em>, denoted $\zeta$.

A user bases (derives) <code>MyModel</code> on one of these classes (or a class ultimately derived from them). An example:
<DD><pre>
&#35;import "DDP"

class MyModel : ExPostSmoothing {
    // declare data members
            Utility(A);
    <details><summary>// Optional methods to replace built-in versions</summary>
            FeasibleActions(A);
            Reachable();
    static PreUpdate();</details>
    <details><summary>// Optional methods to accommodate new solution methods (advanced)</summary>
           thetaEMax();
           ActVal();
           Smooth();</details>
    }
</pre></DD>

The continuous state &zeta; determines the form of Bellman's for choice-specific values, which integrates out the IID state vectors, &zeta;, &epsilon; and &eta;. Bellman equation solution methods are coded separately from `Bellman`. They are derived from the `Method` class and described in <a href="Methods.ox.html">Methods</a>. Some methods may only operate if the user's model is derived from a compatible class of `Bellman` or has other required characteristics.</p>

Classes of type `Bellman` code the form of Bellman's equation for the specification:
$$\eqalign{
V(\theta^{\,\prime})\quad &\equiv \quad \sum_{\eta}\ \sum_{\epsilon}\left[ \int_{\zeta} V\left(\eta,\epsilon,\eta,\theta^{\,\prime}\right)f(\eta)d\eta \right] P_\epsilon(\epsilon)P_\eta(\eta) \cr
EV(\theta^{\,\prime})\quad &=\quad E_{\alpha,\eta,\theta} \left[V(\theta^{\,\prime})\right] = \sum_{\theta^{\,\prime}} \biggl[ V\left(\theta^{\,\prime}\right)P\left(\theta^{\,\prime}\ ;\ \alpha,\eta,\theta\right)\biggr]\cr
v(\alpha;\zeta,\epsilon,\eta,\theta)\quad &\equiv\quad U(\alpha,\epsilon,\eta,\theta,\gamma) + \zeta_\alpha + \delta EV(\theta^{\,\prime})\cr
V(\zeta,\epsilon,\eta,\theta)\quad &=\quad\max_{\alpha\in A(\theta)}\ v(\alpha;\zeta,\epsilon,\eta,\theta)\cr}$$

The integration over $\zeta$ is carried out by the virtual `Bellman::thetaEMax`() or its replacement and does not have to be coded by the user. The default method,  `Bellman::thetaEMax`(), assumes that $\zeta$ takes on one value, 0, with density $f(0)=1$.  (Another way to think of it:  $\zeta$ is an empty vector.)   Thus, the default does no integration.</p>

Choice probabilities are stored conditional on $\eta$ and $\theta$.  This requires summing over $\epsilon$ and integrating over $\zeta$. Another virtual method, `Bellman::Smooth`(), carries out the smoothing of choice probabilities, but only on a final iteration (after convergence in an infinite horizon environment). In the default, choice probabilities are not smoothed.  That is, conditional choice probabilities are either 0 or 1 based on whether the action $\alpha$ has maximum value or not. The derived class `ExPostSmoothing` allows for ex-post smoothing of choice probabilities without the presence of $\zeta$.</p>

<li>User-Contributed Elements of <code>MyModel</code> and <code>MyCode</code></li>
<OL class="chapter">
<LI>Utility()</LI>
<code>MyModel</code> must supply a replacement for `Bellman::Utility`(). Since utility depends on the current state, the method must be automatic (not static).
<DD><pre>
&#35;import "DDP"

struct MyModel : ExPostSmoothing {
    // define data members and methods
    Utility(A);
    }
MyModel::Utility(A) {
    return  {a vector of utility values given the feasible actions <code>A</code> }
    }
</pre></DD>
<LI>Reachable state creator</LI>

A state is unreachable if it cannot occur given initial conditions.  For example, a person cannot have 20 years of labour market experience at age 18. Including unreachable states in the state space wastes computation and storage but does not cause any errors.  <code>MyModel</code> <em>can optionally</em> provide a replacement for the virtual `Bellman::Reachable`() method.  The built-in version of <code>Reachable</code> returns TRUE, meaning all states are marked as reachable.   The user can provide a replacement with returns an indicator for whether the current state is reachable or not.</p>

<DD>Example.  To mark states at which state variables $x$ and $y$ greater than 5 as unreachable:
<pre>MyModel::Reachable() {
    return ! (CV(x)+CV(y)&gt; 5);
    }
</pre></DD>

<LI>Restricted Feasible Action spaces / matrices </LI>

<code>MyModel</code> <em>can optionally</em> provide a replacement for the virtual `Bellman::FeasibleActions`() method to make the feasible choice set to vary with the endogenous state $\theta$.  That is, the action space $A$ is really $A(\theta)$.  Again, the default is that all states constructed from the action variables added to the model.

<DD>Example.  Only action vectors with <code>d</code> less than or equal to the value of state variable <code>x</code> are feasible.
<pre>MyModel::FeasibleActions() { return CV(d) &lt;= CV(x); }
</pre></DD>

<LI>Hooks and Update Time</LI>

<code>MyModel</code> can use `Hooks::Add`() to have a static method/function called at different points in solution methods. <code>MyModel</code> can also use `DP::SetUpdateTime`() to set when solution methods should update transition probabilities and utility of actions.  This allows transitions and utility to depend on fixed and random effect variables, but if they do not wasted computations can be avoided by updating higher up in the process.</p>

<LI>Value-related routines (advanced)</LI>

<code>MyModel</code> can supply replacements for `Bellman::thetaEMax`(), `Bellman::ActVal`(), and `Bellman::Smooth`().  Many of the derived classes of Bellman already specialize these operations.  It is unlikely a user would need to do this.

<LI>Auxiliary Variables and ZetaRealization</LI>

<code>MyModel</code> can add `AuxiliaryValue`s and a `ZetaRealization` for simulating outcomes and accounting for partial observability of the state. <code>MyCode</code> must sandwich the commands that add actions and states to the model between calls to <code>DPparent::Initialize(&hellip;)</code> and <code>DPparent::CreateSpaces(&hellip;)</code>.  <code>MyModel</code> can supply its own version of these two methods, but then they <em>must</em> call the parent versions.  If <code>MyModel</code> does not have its own versions, then the prefix <code>DPparent::</code> is not needed because a reference to <code>Initialize()</code> will refer to the parent's version.</p>
</OL>
</OL>

<HR/><a name="static"/><H1>STATIC COMPONENTS OF THE BELLMAN CLASS</H1>

<OL class="contents">
<LI><a href="#DP">DP static elements</a></LI>
<LI><a href="#Groups">Groups</a></LI>
<LI><a href="#Debug">Debug Output and Options</a></LI>
</OL>

<OL class="body">
<a name="DP"><LI>DP static elements</LI>

`DP` is the base class for <em>all</em> aspects of DDP models. All variables (also known as members) of the base class are <em>static</em>, which means there is only one storage location for all objects of the class. That is, these values are shared by every object derived from `DP`. Non-static or automatic members are only defined in the derived classes. Different derived classes from `DP` organize the various aspects of dynamic programming.  These include:

    <DD>The problem itself, which is based on the derived `Bellman` class and discussed above. Non-static elements of the model which must vary across points in the state space  are defined in `Bellman`. </DD>

   <DD>The endogenous state space $\Theta$ is stored as an array `Theta` of objects of the user's problem class.  This array is a "static global
   variable" so access to it is somewhat limited. The code is designed so that the user need not and should not access <code>Theta</code> directly.</DD>

    <DD>Groups of problems, which are stored in the derived `Group` class, discussed <a href="#Groups">below</a>. Groups keep track of different DP problems defined by `TimeInvariant` states defined in <a href="Variables.ox.html#Fixed">Variables.ox.html</a>, fixed and random effects. Each value of the invariants implies  a point $\gamma$ in the group space $\Gamma$.  The group space is stored as an array `Gamma` of Group objects, a  global static variable in DP.ox.  Direct access to `Gamma` is limited.</DD>

    <DD>Tasks: A `Task` is designed to iterate over objects in the overall state space and carry out specific work. You can think of a task an <em>operators</em> on part of the overall state space. Derived tasks include `Method` for coding solution algorithms. Methods are discussed in  <a href="Methods.ox.html">Methods</a>. </DD>

    <DD>`Data` is a derived Task which includes all aspects of storing realizations of a DP, such as simulations, predictions and external data for estimation. Data and its derived classes are defined in <a href="Data.ox.html">Data</a>.</DD>

    <DD>State Space Creation: Different tasks are defined to set up $\Theta$ and $\Gamma$.</DD>

    <DD>Nested Tasks: Other tasks are set up to iterate over states to compute utility, transitions, etc. These tasks are often created and stored as members of another task so that a nested solution algorithm is implemented.</DD>

<a name="Groups"><LI>Groups</LI></a>

By default <code>MyModel</code> defines a single decision making process.  A single solution to the dynamic program is then required to solve the model. Another way to say this is that there is no heterogeneity in the environment across agents. If a homogeneous model is applied to data, then different agents would have different outcomes solely because of different realizations along the solution path.  Differences in initial states are included in the homogeneous case as long as each agent has the same probability distribution across initial states.</p>

Most applications of dynamic programming involve more than one problem.  DDP handles this by allowing for <code>MyModel</code> to include more than one problem to be solved by using Groups. <span class="n">DDP</span> tries to be smart about storage and computation when accounting for different solutions.  It does <em>not</em> simply duplicate everything about a single model for each group. A `Group` is a class derived from `DP` which stores key aspects of the solution to the model that will be used for prediction and estimation. A <em>group</em> is defined as a unique value of $\gamma$.</p>

Elements of the group vector must be derived from the `TimeInvariant` class of state variables. Time Invariant states are classified as either <em>fixed</em> or <em>random</em> effects, derived respectively from `FixedEffect` and `RandomEffect`. Further `FixedEffectBlock`s can be used to represent `SubEffect`s and `RandomEffectBlock`s can be used to represent `CorrelatedEffect`s.</p>

The user creates multiple groups by adding time-invariants to the model using `DP::GroupVariables`().
<DD>Example: Create different DP programs for men and women, and allow people to differ in ability.<pre>
    enum{male,female,Ngender}
    enum{lo,hi,Nability}
    Initialize(...);
    ...
    GroupVariables(
       a = new RandomEffect("a",Nability),
       g = new FixedEffect("sex",Ngender),
       );
    ...
    CreateSpaces(...);
</pre></DD>
The set of all distinct groups is the <em>group space</em>, and is denoted $\Gamma$. The group space is kept separate from the state space $\Theta$ in order to economize on storage. Only results that need to be held for later used are stored in $\Gamma$ and the state space is reused for each solution of the problem.</p>

<a name="Debug"><LI>Debug Output and Options</LI></a>

The `DPDebug` class is the base for output routines and other tasks that are related to debugging and reporting.</p>

Most classes in niqlow have a <code>Volume</code> member which will determine how much output is produced during execution. In particular `DP::Volume` controls how much output about the dynamic program is put out during and after a solution method. You can get more output by turning up the <code>Volume</code>.  See `NoiseLevels`.  For example, <code>DP::Volume = NOISY;</code> will produce the most output and <code>DP::Volume = SILENT;</code> the least.  The default setting for all <code>Volume</code> variables is <code>QUIET</code>, one level above <code>SILENT</code>.</p>

When you call `DP::Initialize`() it opens a <em>timestamped</em> log file. Output that is expected to be very large, like dumps of the value function or state transitions, are sent there instead of to the screen.  Other parts of niqlow will write to other timestamped log files.</p>

</OL>

</OL>



@author &copy; 2011-2018 <a href="http://econ.queensu.ca/~ferrall">Christopher Ferrall</a></dd>

<a name="auto"><hr><h1>Documentation of Items Defined in Bellman.ox <a href="#"><span class="skip"><abbr title=" Back to top">&nbsp;&#8679;&nbsp;</abbr></span></a></h1></a>

**/
