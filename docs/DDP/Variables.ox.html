<?xml version="1.0" encoding="UTF-8"?>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="stylesheet" type="text/css" href="oxdoc.css">
<link rel="stylesheet" type="text/css" media="print" href="print.css">
<script type="text/javascript" async  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_CHTML"></script>
<title>Variables.ox - Derived Dynamic Programs</title>
</head>
<body>
<div class="header">
[ <img class="icon" src="icons/uplevel_s.png">&nbsp;<a href="..\default.html">Up Level</a> |
<img class="icon" src="icons/project_s.png">&nbsp;<a href="default.html">Project home</a>
 | <img class="icon" src="icons/index_s.png">&nbsp;<a href="index.html">Index</a>
 | <img class="icon" src="icons/hierarchy_s.png">&nbsp;<a href="hierarchy.html">Class hierarchy</a> ]</div>
<h1><span class="icon"><img class="icon" src="icons/file.png">&nbsp;</span><span class="text">Variables.ox</span></h1>

Describes how to represent actions, states, and other discrete quantities in your DP model.
<a href="#auto"><span class="skip"><abbr title=" Skip down to items defined in Variables.ox">&nbsp;&#8681;&nbsp;</abbr></span></a>
<P/>
<OL class="contents">Contents
<LI><a href="#OV">Overview</a></LI>
<LI><a href="#ActionVariables">Action Variables:</a> the choices your agent makes at each state</LI>
<LI><a href="#StateVariables">State Variables:</a> values that define the state of the problem; how to use them and how to create new ones.</LI>
<LI><a href="#Clock">The Clock:</a>  a special state variable for keeping time in DDP</LI>
<li><a href="#Fixed">Time Invariants:</a> solving different DP problems based on values that differ across agents but not during the agent's problem; these are analogous to <em>random</em> and <em>fixed effects</em> in panel data models.</li>
<li><a href="#Auxiliary">Auxiliary Values:</a> tracking functions of actions and state variables in data sets; these play an important role in estimation by matching data that depends on the current outcome without expanding the space.</li>
<LI><a href="#Continuous">Conditional Continuous Choices:</a> optimizing at points in the state space;  <mark>this is in progress</mark></LI>
<li><a href="#Volume">Volume:</a> (getting output specific to a variable)</li>
</OL>
<P/>
<OL class="body">
<P/>
<li id="OV">Overview</li>
<P/>
<DT>A variable in a DP model is an object derived from <a href="Shared.ox.html#Quantity">Quantity</a> and can be of various types:</DT>
<P/>
<DD>The <a href="Variables.ox.html#ActionVariable">ActionVariable</a> class represents a choice in the model (such as whether to work or not) and is an element of the action vector <span class="expressions">\(\alpha\)</span>. </DD>
<P/>
<DD>The StateVariable class is designed to be a member of one of the discrete state vectors (<span class="expressions">\(\epsilon,\eta,\theta,\gamma\)</span>).  There are many derived types of state variables explained below.</DD>
<P/>
<DD>The AuxiliaryValue class represents values that depend on actions and states but are not required to solve the model.  They are members of the auxiliary vector <span class="expressions">\(\chi\)</span>.</DD>
<P/>
<p>As explained elsewhere, the user creates a class for their DP model.  The class should declare a <code>static</code> data member for each variable of these types.  New objects of the appropriate class are created and then assigned to the variables while the model is being built: after calling DP::Initialize() and before calling DP::CreateSpaces().</p>
<P/>
<p>Creating an object for a variable does <em>not</em> add the variable to the model. It must be added to the model after being created by calling the corresponding function during the build phase:</p>
<P/>
<DD>Send action variables to DP::Actions() to add them to <span class="expressions">\(\alpha\)</span></DD>
<DD>Send state variables to DP::EndogenousStates() to add them to <span class="expressions">\(\theta\)</span> (the non-specialized state vector).</DD>
<DD>Send IID state variables to either DP::SemiExogenousStates() or DP::ExogenousStates() to add them to <span class="expressions">\(\eta\)</span> and <span class="expressions">\(\epsilon\)</span>, respectively.</DD>
<DD>Send fixed and random effect variables to DP::GroupVariables() to add them to <span class="expressions">\(\gamma\)</span> (they will be assigned to the appropriate sub vector <span class="expressions">\(\gamma_f\)</span> or <span class="expressions">\(\gamma_r\)</span>.)</DD>
<DD>DP::AuxiliaryOutcomes() adds auxiliary values to <span class="expressions">\(\chi.\)</span></DD></p>
<P/>
<LI id="ActionVariables">Action Variables</LI>
<P/>
<OL class="chapter">
<LI id="Basics">Basics</LI>
<P/>
<p>The action vector <span class="expressions">\(\alpha\)</span> is the vector of discrete actions chosen conditional on the state of the DP.  A generic element of <span class="expressions">\(\alpha\)</span> is denoted <var>a</var>.  An action variable takes on <span class="expressions">\(a.N\)</span> different values. The action vector includes <span class="expressions">\(\alpha\)</span>.N variables, denoted a<sub>0</sub> through a<sub>(<span class="expressions">\(\alpha\)</span>.N)&oline;</sub>. </p>
<P/>
<p>Action variables are represented as an <a href="Variables.ox.html#ActionVariable">ActionVariable</a> and are added to <code>MyModel</code> and to <span class="expressions">\(\alpha\)</span> using DP::Actions().  Calls to <code>Actions()</code> and other model-building routines is part of <code>MyCode</code> that user writes unless the class they are using includes the definition of the action variables.</p>
<P/>
<p>In the basic definition of a DDP model, <span class="expressions">\(A\)</span> is the set of possible actions. In <span class="n">DDP</span> the set of actions is built up by adding action variables to <span class="expressions">\(\alpha\)</span>.  So <span class="expressions">\(A\)</span> emerges from the properties of the variables added to <span class="expressions">\(\alpha\)</span>.</p>
<P/>
<p>The <em>Possible Actions Matrix</em> <span class="expressions">\(A\)</span> is the matrix of all possible action vectors. It is the Cartesian product of the actions added to <span class="expressions">\(\alpha.\)</span>  The word <em>possible</em> is used instead of <em>feasible</em>, because this notion of <span class="expressions">\(A\)</span> is constructed mechanically from properties of the actions.  It has nothing to do with the interpretation of the actions.  Feasible actions are defined below.</p>
<P/>
<p>An <em>action</em> refers to a particular value of the action vector <span class="expressions">\(\alpha\)</span>, which in turn is  a row of <span class="expressions">\(A\)</span>. An action variable refers to a column of <span class="expressions">\(A\)</span>, but note that values of an action variable are repeated within the column. DDP constructs <span class="expressions">\(A\)</span> when <code>MyCode</code> calls <code>CreateSpaces()</code>.</p>
<P/>
<DT>Alternative Notation</DT>
<P/>
<p>Discrete choice is described in two ways other than the one above used in <span class="n">DDP</span>. For example, suppose there are two action variables and 6 total action vectors:
 <span class="equation">$$\eqalign{
 &\alpha = (a_0,a_1)\cr
 &a_0.N = 3\cr
 &a_1.N = 2\cr
 &\alpha.D =6\cr}$$</span>
 Some papers would treat this as a <em>single action</em> with six values. And/or papers may define a vector of 6 indicator variables to denote which choice was made: <var>d<sub>i</sub>=I{a=i}</var>.</p>
<P/>
The three different approaches to coding discrete choices are illustrate in this table:
<dd><pre>
   DDP Approach       | Single Action |    Indicator Vectors
   a0         a1      |       a       |    d0  d1  d2  d3  d4  d5
----------------------+---------------+----------------------------
   0          0       |       0       |    1   0   0   0   0   0
   1          0       |       1       |    0   1   0   0   0   0
   2          0       |       2       |    0   0   1   0   0   0
   0          1       |       3       |    0   0   0   1   0   0
   1          1       |       4       |    0   0   0   0   1   0
   2          1       |       5       |    0   0   0   0   0   1
</pre></DD>
<P/>
<p>One reason to use an action vector like <span class="expressions">\(\alpha\)</span> is that each variable can be interpreted as a dimension of choice.  There is no obvious interpretation of <q>a=3</q> in the table, and the interpretation would change with the dimensions of the action variables. This approach would force <code>MyModel</code> to decode into an action vector to make their code look like a mathematical model.</p>
<P/>
<p>Another reason to use the DDP approach: the action vector approach makes it natural to impose feasibility conditions on the choice set, as discussed below.</p>
<P/>
<p>Indicator vectors make it possible to write any utility as a sum: <span class="expressions">\(U = \sum_k d_k u_k\)</span>. But as with the single action approach the interpretation is not obvious and <span class="expressions">\(U()\)</span> will in no way resemble usual mathematical notation for an objective.</p>
<P/>
<LI>Actual, Current and Empirical Values of an Action Variable</LI>
<P/>
Usually an action variable can be an object of the base <a href="Variables.ox.html#ActionVariable">ActionVariable</a> class.  The user rarely needs to define a derived class.
<P/>
<DT>Current Value</DT>
    <span class="n">DDP</span> requires <code>MyModel</code> to handle/process the full matrix of feasible actions in utility and transitions. For this reason, <code>MyModel</code> will rarely if ever access the current value of an action, <code>a.v</code>. The vector of values of an action variable <span class="expressions">\(a\)</span> is returned by <code>CV(a).</code></p>
<P/>
<DT>Actual Value</DT>
<P/>
    Optionally, the user can create a class derived from <a href="Variables.ox.html#ActionVariable">ActionVariable</a> and supply a Discrete::Update function with it. This allows the user to associate a meaningful value for the numbers 0 to N&oline;, stored as <code>a.<a href="Shared.ox.html#Discrete___actual">actual</a></code>. <span class="n">DDP</span> updates an action each time the problem is resolved, so actual values can depend on <a href="Shared.ox.html#Parameter">Parameter</a> values. AV(a) will return the actual values of <code>a</code> that correspond to each feasible action vector <span class="expressions">\(\alpha\)</span>. The default virtual Discrete::Update() simply sets actual to the vector &lt; 0 : N-1 &gt;.</p>
<P/>
<DT>Example of Custom <code>Update()</code></DT>
<P/>
Unless you want to provide actual values for an action you do not need to create a derived class. Let <var>a</var> denote a discrete choice of hours to work each week.  The maximum number of hours, <var>H</var>, depends on a parameter which can differ across individuals but is constant across the state space.
<DD>Actual Hours action variable<pre>
struct Hours : ActionVariable {
        decl H;
        Hours(const N,const H);
        Update();
        }
Hours::Hours(const N,const H) {
        this.H = H;
        ActionVariable("h",N);
        }
Hours::Update() {
        actual = AV(H)* (vals / N);
        }
&vellip;
MyModel::MaxH() { return CV(hasch) ? 30 : 50; }
&vellip;
MyModel::Initialize() {
   &vellip;
   GroupVariables(hasch = new FixedEffect("",2));
   Actions(h = new Hours(5,MyModel::MaxH));
   &vellip;
   }
MyModel::Utility() {
        return CV(wage)*CV(h);
        }
</pre></DD>
The code segment allows the maximum hour to be 30 if the person has a (young) child, otherwise 50 hours.  And then lets each type choose 5 different levels of hours between 0 and their max hours.  Utility will be total earnings.</p>
<P/>
<LI>Possible and Feasible Actions</LI>
<P/>
<span class="expressions">\(A\)</span> is defined as the set of possible actions, built up by adding action variables to <span class="expressions">\(\alpha\)</span>.  All possible actions is the matrix:
<span class="equation">$$    A \equiv \times_{j=0,\dots, \alpha.N-1 } \{ 0, 1, \dots, a_j.N-1 \}$$</span>
An action vector <span class="expressions">\(\alpha\)</span> is a <em>row</em> of the matrix A. An action variable is a column of <span class="expressions">\(A\)</span>.  Its position is the property <code>a.pos</code>.</p>
<P/>
<p><em>Feasibility</em> is a property <code>MyModel</code> imposes on <span class="expressions">\(\alpha\)</span>. The model may say that some logically possible actions cannot be chosen because they do not make sense given the interpretation of <span class="expressions">\(\alpha\)</span>.  Or some actions are ruled infeasible for convenience to avoid calculations that are relatively unimportant. We can write feasibility as a property of the state.  Or it can be written as a function of the state, which is more standard.  Using both versions, the <b>feasible actions</b> at <span class="expressions">\(\theta\)</span> is a matrix property:
<span class="equation">$$\forall \theta \in \Theta,\qquad A(\theta) \equiv \theta.A \subseteq A.$$</span>
<P/>
<p>Bellman::FeasibleActions(): by default all possible actions are feasible unless <code>MyModel</code> says otherwise.  <span class="expressions">\(A(\theta) \equiv A\)</span> for all endogenous states. This default assumption is produced by including a built-in virtual method, <code>Bellman::FeasibleActions()</code>. meaning that <code>MyModel</code> can replace it with its own version.  This is explained in <a href="Bellman.ox.html">Bellman</a>.</p>
<P/>
<DT>The A List</DT>
<P/>
DP::CreateSpaces constructs the possible matrix A, stored as the first element of a list: <var>A</var> &harr; <code>A[0]</code>. It then calls <code>FeasibleActions(A)</code> for each reachable state <span class="expressions">\(\theta\)</span>. Every time a different value is returned by <code>FeasibleActions()</code> a new matrix is added to the A list.  The index into the list is then stored as <a href="Bellman.ox.html#Bellman___Aind">Aind</a>.  That is, there is not a different matrix at each <span class="expressions">\(\theta.\)</span> Instead there is a list of different feasible matrices and <span class="expressions">\(A(\theta)\)</span> is really an index into that list.  </p>
<P/>
<p>The user's (optional) feasible action method should determine feasibility using the action variables stored in the derived DP model.  So if <code>a</code> contains an <code>ActionVariable</code> its value are available as <code>CV(a)</code>. In short, <span class="expressions">\(\theta\)</span>.A &harr; <code>A[Aind]</code>. If <code>MyModel</code> does not specify feasible actions, then <code>Aind = <span class="expressions">\(\theta\)</span>.j = 0</code> for all states.</p>
<P/>
<p>The A list contains the <em>actual</em> values not the <em>current</em> values. If the user provides an Discrete::Update() for a derived class of action variable, then <code>A[Aind]</code> is the matrix of actual values. Since the default is that actual values equal current values (<code>a.actual[a.v] = a.v</code>), then <code>A[Aind]</code> is always possible to use. The uncoded list of matrices is available as <a href="DDPShared.ox.html#Alpha___Matrix">Matrix</a>.</p>
</OL>
<P/>
<hr><LI id="StateVariables">State Variables</LI>
<P/>
<OL class="chapter"> Content of the StateVariable Section
<LI><a href="#SOV">Overview</a></LI>
<LI><a href="#SVT">State Variable Transitions</a></LI>
<LI><a href="#SP">Augmented and Specialized State Variables</a></LI>
<LI><a href="#ASV">Creating a new or derived Autonomous State Variable</a></LI>
<LI><a href="#example">Example of a new state variable</a></LI>
<LI><a href="#further">Further Considerations</a></LI>
<LI><a href="#SB">State Blocks</a></LI>
<LI><a href="#CSB">How to Create a State Block</a></LI>
<LI><a href="#ASB">Accessing  State Block Values</a> </LI>
<LI><a href="#Trans">The Overall Transition</a></LI>
</OL>
<P/>
<OL class="chapter">
<LI id="SOV">Overview</LI>
A state variable <var>s</var> is a <a href="Shared.ox.html#Discrete">Discrete</a> quantity.  It is defined by at least the 3 required elements:
<DT><a href="Shared.ox.html#Quantity___L">L</a> </DT><DD>a short tag for the variable (can be blank, <q></q>)</DD>
<DT><a href="Shared.ox.html#Discrete___N">N</a> </DT><DD>The number of values it takes, which are 0 &hellip; N&oline;</DD>
<DT>StateVariable::Transit()</DT>
<DD>The transition for the variable, <span class="expressions">\(P_s(s\prime | \alpha,\eta,\theta)\)</span>. </DD>
<DD>The transition can depend on other state variables and actions.  These dependencies are created by sending the other variable objects when creating the state variable.</DD>
<DT>Many predefined state variable classes are available that correspond to ones in the literature, so a user may not need to define a new one.</DT>
<DD>Special or customized state variables can be created using ways to <em>augment</em> another state variable. For example, a state variable can be "frozen" or "reset" under certain conditions by augmenting it and without recoding the transition.</DD>
<P/>
<DT>State variables are classified by how their transitions relate to actions and the current value and transitions of other state variables.   Either they are </DT>
<DT><q>Autonomous</q>
<DD>which means their <em>transition</em> to new states does not have to be coordinated with transitions of other states;</DD>
<DD>The transition of autonomous variables can depend on the current values other states.</DD>
<DT> or they are </DT>
<DT><q>Coevolving</q></DT>
<DD>in which case they must be a member of a StateBlock.</DD>
<DD>Within a state block the innovations of member state variables can be correlated in an arbitrary way.</DD>
<P/>
<p>Most aspects of DP models can be handled by autonomous variables because the transition can depend on current values of other variables. Only certain kinds of correlations between two or more variables require coevolving variables in a block.</p>
<P/>
<p>The model places discrete state variables/blocks into one of four vectors.
<table id="statevectortable" class="overview" width="100%" border="2"><caption>State Variable Vectors</caption>
<tr><td></td><th colspan="2">IID Transitions</th><th>General Transition</th><th colspan="2">No Transitions (Group Variables)</th></tr>
<tr><td></td><td>Exogenous<br>(<span class="expressions">\(\epsilon\)</span>) </th><td>Semi-Exogenous<br>(<span class="expressions">\(\eta\)</span>) </td><td>Endogenous<br>(<span class="expressions">\(\theta\)</span>)</th><td>RandomEffect<br/>(<span class="expressions">\(\gamma_r\)</span>)</td><td> FixedEffect<br/>(<span class="expressions">\(\gamma_f\)</span>)</tr>
<tr><td>Generic Element</td><td>e</td><td>h</td><td>q</td><td>r</td><td>f</td></tr>
<tr><td>Form of <span class="expressions">\(P\)</span><sub>s</sub></td><td colspan="2"><span class="expressions">\(P_s(s^\prime)\)</span></td><td><span class="expressions">\(P_s(s^\prime|\alpha,\epsilon,\eta,\theta)\)</span></td><td colspan="2"><span class="expressions">\(g^\prime=g\)</span></td></tr>
<tr><td>Explanation</td><td colspan="2">IID, exogenous to everything.</td><td>Transition can depend on current states and actions.</td><td colspan="2">value is fixed for this problem.</td></tr>
<tr><td>Special form of<br/> <span class="expressions">\(P_q\)</span>, <span class="expressions">\(q\in\theta\)</span>, <span class="expressions">\(q\neq s\)</span></td><td>cannot enter <span class="expressions">\(P_q\)</span></td><td colspan="2">can enter transition of other variables</td><td colspan="2">can enter but<br>see DP::SetUpdateTime</td></tr>
<tr><td>Explanation</td><td><span class="expressions">\(q\)</span> independent of <span class="expressions">\(\epsilon\)</span>, given <span class="expressions">\(\alpha\)</span></td>
<td colspan="2"><span class="expressions">\(\eta\)</span> and <span class="expressions">\(\theta\)</span> can affect <span class="expressions">\(q\)</span></td><td>default <span class="expressions">\(r\)</span> can <em>only</em> enter <span class="expressions">\(U()\)</span></td><td>can enter <span class="expressions">\(P_q\)</span></td></tr>
<tr><td>Computing Implication</td><td colspan="2">Compute &amp; store <span class="expressions">\(P_\epsilon\)</span> and <span class="expressions">\(P_\eta\)</span> once on each solution.</td>
<td>Compute and store <span class="expressions">\(P_\theta\)</span> at each <span class="expressions">\(\theta\)</span>, store as a <em>matrix</em> in  <span class="expressions">\(\alpha\)</span> and <span class="expressions">\(\eta\)</span> </td><td>Store <span class="expressions">\(P^\star(\alpha|\dots\gamma_r)\)</span></td><td>Reuse space for each fixed effect. </td></tr>
</table>
<P/>
<details><summary><b>Example</b> <br>Include an Semi-Exogenous IID jump process and an Endogenous tracker of its previous value to a DDP model:</summary>
<DD><pre>class MyModel : DPparent {
    &vellip;
    static decl e, q;
    &vellip;
    static Initialize();
    }
&vellip;
MyModel::Initialize() {
    DPparent::Initialize(new MyModel());
    &vellip;
    ExogenousStates(e = new SimpleJump("iid",5));
    EndogenousStates(q = new LaggedState("lag",e));
    &vellip;
    CreateSpaces();
    }
</pre></DD></details>
<P/>
<LI id="SVT">State Variable Transitions</LI>
<P/>
<DT>The overall state transition is  computed as follows</DT>
<span class="equation">$$P\left(\epsilon^{\,\prime},\eta^{\,\prime},\theta^{\,\prime}\ |\ \alpha,\epsilon,\eta,\theta\right) =
P_\epsilon(\epsilon^{\,\prime}) P_\eta(\eta^{\,\prime}) P_\theta\left(\theta^{\,\prime}\ |\ \alpha,\eta,\theta\right).$$</span>
That is, the joint probability distribution of all state variables next period is the product of the probabilities of the three state vectors.  So the vectors evolve independently conditional on the current state. Further, the IID nature of <span class="expressions">\(\epsilon\)</span> and <span class="expressions">\(\eta\)</span> mean that their probability is constant across current states and actions.  In turn,
<span class="equation">$$\eqalign{
P_\epsilon(\epsilon^{\,\prime}) &= \prod_{k=0\dots \epsilon.N-1} P_{e_k}\left(e^{\,\prime}_k\right)\cr
P_\eta(\eta^{\,\prime}) &= \prod_{k=0\dots \eta.N-1} P_{e_k}\left(e^{\,\prime}_k\right)\cr
P_\theta\left(\theta^{\,\prime}\ |\ \alpha,\eta,\theta\right) &= \prod_{k=0\dots \theta.N-1} P_{q_k}\left(q^{\,\prime}_k\ |\ \alpha,\eta,\theta\right).\cr}$$</span>
<P/>
<DD>It is important to note that e<sub>k</sub>, h<sub>k</sub> and q<sub>k</sub> represents either an autonomous state variable or a whole state block, which is responsible for returning the joint transition of its coevolving members.</dd>
<P/>
<DT>Autonomous</DT>
    <DD>Let the value of a state variable <var>s</var> realized next period be denoted <var>s'</var>.  The probability that <span class="expressions">\(s'\)</span> takes on the value <var>z</var> in the next period be written generally as
    <span class="equation">$$P(s' = z | \alpha,\epsilon,\eta,\theta) = p_s(z,\alpha,\epsilon,\eta,\theta).$$</span></DD>
<P/>
<DT>Exogenous</DT>
    <DD>State Variables classified as (fully) Exogenous are denoted generically as <em>e</em> and are elements of the vector <span class="expressions">\(\epsilon\)</span>.</DD>
<P/>
<DT>Endogenous</DT>
    <DD>State Variables classified as Endogenous are denoted generically <em>s</em> and are elements of the vector <span class="expressions">\(\theta\)</span>.</DD>
<P/>
<DT>A single variable that is both Exogenous and Autonomous would satisfy the usual definition of a simple IID random variable.</DT>
    <DD>In that case
    <span class="equation">$$P(e' = z | \alpha,\epsilon,\eta,\theta) = p_e(z).$$</span>
    That is, the transition probabilities are exogenous to the current actions, state values and their transitions.</dd>
<P/>
<DT>Coevolving</DT>
    <DD>A State Variable is Coevolving if it is not autonomous, meaning it is <em>not</em> conditionally independent of all other
    variables. Variables whose transitions are dependent on each other must all be a member of a StateBlock.</DD>
<P/>
<DT>Endogenous and Autonomous</DT>
    <DD>An endogenous and autonomous state has transition probabilities that can depend on the current state and action, but they cannot be correlated with the transition of any other state variable:
    <span class="equation">$$Prob(q\prime = z | \alpha,\epsilon,\theta,\chi) = P_q(z,\alpha,\epsilon,\theta,\chi).$$</span>
    That is, the transition probabilities are exogenous to the current actions, state values and their transitions. Note that an endogenous state variable's transition can depend on exogenous states in <span class="expressions">\(\epsilon\)</span> and <span class="expressions">\(\eta\)</span>.</DD>
<P/>
    <DD>An autonomous StateVariable <code>s</code> has marginal transition probabilities that enter the overall transition probability as multiplicative factors, conditional on current actions, states and parameters.   This is in contrast to Coevolving state variables which are part of a StateBlock. The difference with an Autonomous state is that its transition is jointly distributed with one or more other Coevolving states.</DD>
<P/>
<DT>Predefined State Variables</DT>
<P/>
    <DD><span class="n">DDP</span> comes with the predefined state variables listed above that can represent many processes in estimated models.  But the set is by no means exhaustive and a serious user of <span class="n">DDP</span> will inevitably need include slight variations or wholly new kinds of variables. Although defining a new kind of state variable is not trivial, it can take a less time and be less prone to error than coding from scratch and then modifying all the code to add or modify variables.</DD>
<P/>
<LI id="SP">Augmented and Special State Variables</LI>
<P/>
Some derived classes of state variables play special roles in <span class="n">DDP</span>.  Two major ones are TimeVariables which serve as the <a href="#Clock">DDP clock</a> and TimeInvariants which track variables that are fixed during a DDP and stored in the <span class="expressions">\(\gamma\)</span> vector.  <span class="n">DDP</span> will re-solve the model for each value of <span class="expressions">\(\gamma\)</span>. Your model may include state variables that are already defined in <span class="n">DDP</span> but require some changes to accommodate the environment.  The next section discusses how to create a new derived class for your state variable, but it may be possible to avoid that using the Augmented state variable feature.</p>
<P/>
<p><b>Example:</b>  Suppose your model has a state variable <code>q</code> which is of the RandomUpDown() class.  That is, each period <code>q</code> may go up or down by one unit or remain unchanged depending choices and other state variables.  However, when another state variable <code>h</code> goes from 0 to 1 you want the value of <code>q</code> to become constant and not subject to the RandomUpDown transition. That is, you want to Freeze the current value of <code>q</code> when <code>h</code> is 1.</p>
<P/>
<details><summary><b>Example</b> <br>Augment a base state variable with the Freeze feature.  In this case <span class="expressions">\(q\)</span> increases by 1 with probability 0.5 each
period until the agent chooses <span class="expressions">\(a=1\)</span>.  Then <span class="expressions">\(q\)</span> freezes at its current value from the next period on.</summary>
<DD><pre>class MyModel : DPparent {
    &vellip;
    static decl a, h, q;
    &hellip;
    static Initialize();
    }
&vellip;
MyModel::Initialize() {
    DPparent::Initialize(new MyModel());
    &vellip;
    Actions(a = new ActionVariable("a",2) ) ;
    EndogenousStates(
        h = new PermanentChoice("h",a);
        q = new Freeze(new RandomUpDown("q",10,<0.5;0.5>),h);
    &vellip;
    CreateSpaces();
    }
    </pre></DD>
Notice that a <code>new</code> state variable is passed to the Freeze() constructor.  In essence this underlying random variable is hidden from the model, which only sees the variables passed to DP::EndogenousStates.     What the model sees is the augmented variable <code>q</code> which acts like a RandomUpDown variable unless <code>h=1</code>.  As always, the other state variables or actions that <code>q</code> depends on have to be passed to its creator (or constructor).</details>
<P/>
<p>In fact, Freeze is a special case of a more general type of Augmented state variable, namely a ValueTriggered() state variable.</p>
<P/>
<LI id="ASV">Creating a new or derived Autonomous State Variable</LI>
<P/>
<p>Below is an <a href="#example">example</a> of how to define a new state variable is provided. It shows both a very basic coding which can get the job done but which might be limiting in some ways.  So a second version of the code is shown which is more robust. Several advanced elements of the Ox programming language determine how and why you create a state variable this way. These features may be confusing to someone just starting to program in Ox, especially with no prior experience with object-oriented programming in an interpreted and dynamically-typed language.
    <DD><a href="http://www.doornik.com/ox/oxsyntax.html#ox_syntax_RefClasses">Classes</a>, <a href="http://www.doornik.com/ox/oxsyntax.html#ox_syntax_RefPublic">Structs</a> and <a href="http://www.doornik.com/ox/oxsyntax.html#ox_syntax_RefConstructor">constructor</a> routines</DD>
    <DD><a href="http://www.doornik.com/ox/oxsyntax.html#ox_syntax_RefDerClass">Derived classes</a> and <a href="http://www.doornik.com/ox/oxsyntax.html#ox_syntax_RefVirtual">Virtual methods</a></DD>
    <DD>Assigning objects creates <em>pointers</em> but copying scalars and matrices creates duplicates.  This means that a state variable stored as an object can be copied to several places, each referring to the same thing.</DD></p>
<P/>
<h3>Step-by-step Instructions to Create a New State Variable</h3>
<OL class="steps">
<LI>Duplicate the State Variable Template File</li>
<P/>
<DT>Pick a name for your new kind of StateVariable.</DT>
    <DD> It cannot have spaces or symbols except <em>_</em>. These instructions will refer to <code>&laquo;VarName&raquo;</code> for whatever name you chose.</DD>
<P/>
<DT>Copy <code>niqlow/templates/DynamicPrograms/StateVariable.ox</code> to a file called <code>&laquo;VarName&raquo;.ox</code>. </DT>
    <DD><details><summary>Contents of <code>Source: niqlow/templates/DynamicPrograms/StateVariable.ox</code></summary><pre>
    <object width="100%" height="300" type="text/plain" data="../../templates/DynamicPrograms/StateVariable.ox" border="1" ></object>
</pre></details></dd>
<P/>
<DT id="incorimp">Decide how you want to include your code.</DT>
    <DD>Ox has two compiler directive: <code>#include</code> or  <code>#import</code>.  See the Ox documentation for more details.  If you use  <code>#import &quot;&laquo;VarName&raquo;&quot;</code> then you must create two separate files,  <code>#import &laquo;VarName&raquo;.h</code> and <code>#import &laquo;VarName&raquo;.ox</code>.  If you use <code>#include &quot;&laquo;VarName&raquo;.ox&quot;</code> then the two parts of the code appear in one file.</DD>
<P/>
<LI>Choose a <em>base class</em> to derive your variable from.</LI>
<P/>
    If your variable is closely related to one of the pre-defined variables listed above then you might be able to choose that as your base class. This may (greatly) reduce the new code you have to write.  If you start from scratch then choose as the base class either Random or NonRandom.  These two categories have no effect, but allow DDP to summarize models that include your state variable more accurately. That is, DDP treats random and nonrandom state variables the same way.</p>
<P/>
<LI>Declare needed elements (members and methods). </LI>
<P/>
    <DT>Your new <code>class</code> (or <code>struct</code>) has to know everything necessary to compute the transition of the state variable at any state.</DT>
<P/>
    <DD> One approach would be to access elements of the <a href="DP.ox.html#DP">DP</a> model itself. This would limit the reliability of your code, as it would rely on certain variables being defined and named the same way as you require. Instead, the preferred way to access necessary information is to store it in the members of your class and if necessary use methods to process that information.</DD>
<P/>
    <DT>Any state variable requires two pieces of information when it is created.</DT>
     <DD>a label <code>L</code> and the number of different values it takes on, <code>N</code>.  The constructor for state variables is defined as <code>StateVariable::StateVariable(const L, const N)</code> to ensure these values are set.</DD>
<P/>
    <DT>There is one required and two optional methods that must be provided for each new state variable.</DT>
<P/>
      <DD>The required method is the <em>constructor</em> for the state variable. The optional methods are called <code>Transit()</code> and <code>Update()</code> that compute the transition and update the <em>actual</em> discrete values associated with the state variable. The word optional is somewhat inaccurate, because every state variable must have those functions.  The issue is whether your state variable needs their own versions of them or can they inherit the version from a parent class.</DD>
<P/>
<LI>Code the constructor function</LI>
<P/>
    <DD>How will your code for the state variable get the information it needs stored?  The answer is you make the user pass the location or value of the information when your state variable is created using the <code>new</code> operator.</DT>
    <DD>In Ox a class does not have to have a constructor, but the parent constructors of a derived class are <em>not</em> invoked automatically.  In DDP your state variable has to call the constructor of the base class (or <code>StateVariable()</code> if it is not derived from another class below Random and NonRandom).  So this means you <em>must</em> declare and define a <em>constructor</em> for your state variable which is called by <code>new</code>, if only to ensure that the parent constructor is called.</DD>
<P/>
    <DD>You decide which information the user needs to supply for the variable, make them arguments to the constructor and then store the information in members.  The example below will make all the jargon in the last sentence clearer that trying to explain it at this point. Is a destructor method needed?  The <code>new</code> operator calls the constructor of a class.  The <code>delete</code> operator calls the destructor.  Again, in Ox, neither of these needs to exist, but in DDP a state variable needs a constructor.  Typically it will not need a destructor and here is why: State variables are presumed to exist the whole time the program is running.  DDP does provide a method to clean up a model that is no longer needed to save memory and to reinitialize for a new DP problem. DDP will delete each state variable but it cannot remove dynamically allocated variables defined within classes.  So if your state variable has any <code>new</code> commands that are not paired with a <code>delete</code> in your code, then yes, you should write a destructor which will delete these objects.  However, the chance that not doing this creates a significant memory leak is small given the anticipated use of DDP.</DD>
<P/>
<LI>Code the <code>Transit()</code> method</LI>
    <DT>Besides a constructor, your state variable must also come with a transition.</DT>
<P/>
    <DD>If it is derived from another state variable and your version will follow the same transition then you do not need to write a new one.  That is because <code>Transit()</code> is, in most cases, declared as a <em>virtual</em> method.  So if your state variable has no transition of its own, the one from the parent variable will be called in its place. This is why it must be called <code>Transit()</code>, because it replaces another version of a <code>Transit()</code> that would be called if necessary. <code>Transit</code> will often need to access matrix of current feasible actions at the current state, which is available in Alpha::C that is set every time the point in the state space is changed or initialized.  Each row of <code>Alpha::C</code> is an action vector <span class="expressions">\(\alpha\)</span> each column is an action variable <span class="expressions">\(a\)</span>.  <code>Transit()</code> must report back the transitions of an instance of the state variable from a given current point in the state space.</DD>
<P/>
    <DT>Example: Possible Argument Passed to <code>Transit()</code></DT>
    <DD>The model has two binary choice variables, <span class="expressions">\(i\)</span> and <span class="expressions">\(j\)</span>.  Then the argument passed to <code>Transit()</code>  might look like this:
    <pre>  Alpha::C
  i    j
  0    0
  1    0
  0    1
  1    1
</pre> </dd>
<P/>
    <DT>Your code has to return two items, sent back in an Ox <em>array</em>. </DT>
<P/>
    <DD>The first is a <em>row vector</em> of feasible values: the  values this state could take on next period.  For convenience call this vector <code>F</code>.  That is, suppose one value, say 3, may be feasible only if a certain action is taken.  Then 3 must be in <code>F</code>, even if 3 is not feasible if another action were taken.  The elements of <code>F</code> do not need to be sorted. The other output is a <em>matrix</em> of transition probabilities, <code>P</code>.   The rows of the matrix must match the rows of <code>Alpha::C</code>; the columns must match the columns of the row vector <code>F</code>.  The <var>ij</var> element of <code>P</code> is the probability that your state variable takes on the jth value in <code>F</code> given the agent chooses the ith action in the feasible set.</DD>
<P/>
    <DD>The array returned as the value of <code>Transit()</code> might be sent using code that looks like this:  <code>return {F,P};</code>, presuming you have declared local variables <code>F</code> and <code>P</code> and filled them with the correct information in the correct format. Notice that the only <em>explicit</em> information sent to <code>Transit()</code> is the feasible matrix.  Yet it must send back the transition at a specific state in the state space.  How does your code know what state is the current state?  Further, how does your code know the current value of parameters which might affect the probabilities?  The answer is that the value or, if the quantity is changing like the current state, the <em>location</em> of the value must be stored in a member of the state.  The only way to get this information is through the constructor function discussed above.</DD>
<P/>
    <DT>The example will</DT>
<P/>
<LI><h3>Debug your code and make sure it does what you want it to do.</h3>
</OL>
<P/>
<LI id="example">Example: Previous Occupation State Variable</LI>
<P/>
    To make the example look better, suppose you have decided to set &laquo;VarName&raquo; to be <q>MyStateVar</q>.  This will be used wherever the name of the new derived class belongs. In math notation we will refer to the new state variable as <var>y</var>.  But in code  <var>y</var> might not be descriptive enough.  Instead, you might add <var>y</var> to the DP model with code that looks like this:
<DD><pre>decl mystate;  // in the <code>class</code> definition of MyStateVar
&vellip;
mystate = new MyStateVar("y",4,&hellip;);
EndogenousStates(mystate);
</pre>
The <q>&hellip;</q> is not literal.  It is there because in this example the constructor <code>MyStateVar()</code> will require other arguments.  The state variable is stored in an Ox variable called <code>mystate</code>, but we will refer to it as <var>y</var>, which is the label given to it.</dd>
<P/>
<DT>What is <var>y</var> supposed to be? </DT>
<P/>
<DD>It is an indicator for the <em>previous</em> value of another state <var>x</var>, but only if a binary choice variable <var>i</var> is 1 last period.  For example, if <code>x</code> is an occupation code and the choice variable <code>i</code> indicates a choice to work, then <code>y</code> equals the occupation the person worked at last period if they did work.  Otherwise <code>y</code> should take on the value 0.  Simply put, the value of <var>y</var> next period is <var>y' = ix</var>.  First, the <var>y</var> process as the feasible state next period:
<pre>y' = ix
</pre>
Now, as a transition probability:<pre>
  Prob(y' = z) = 1 if z = ix
                0 if z &ne; ix.
</pre></dd>
<P/>
<DD>Because the transition probabilities for <var>y</var> are 0 and 1, <code>MyStateVar</code> should be classified as a NonRandom state variable.  This is a special case of an <em>autonomous</em> process because the probabilities do not depend on the next values of the other states, such as <code>x'</code>.  If that were the case, the user has to create a StateBlock which handles the transitions for multiple Coevolving variables. (DDP has no way of knowing for sure that the probabilities are always 0 and 1, at all states and for all possible parameter values, so that is why you manually categorize it as nonrandom because you know that the 0 and 1 are hardcoded into the <q>DNA</q> of the state variable.)  Because the transition depends on the action chosen <var>y</var> is nonrandom but it is not deterministic.  A deterministic random variable would be something like a seasonal cycle.</DD>
<P/>
<DT>Once the program is running some of the members of <code>mystate</code> might have these values:</DT>
<dd class="example"><pre>
    mystate  {
        .L = "y"
        .N = 4
        .v = 0
        .vals = <0,1,2,3>
        .pos = 1
        &vellip;
        }
</pre>
That is, <var>y</var> takes on 4 different values (0,1,2,3).  At the current state it happens to have value <code>v=0</code>. It also happens to be the second state variable in the state vector (<code>pos=1</code>). </dd>
<P/>
<DT>Next, suppose  &laquo;VarName&raquo; has been added to a <em>finite horizon</em> model with three state variables <var>x</var>, <var>y</var> and <var>z</var>.  </DT>
<P/>
<DD>At some point in the process suppose the current value of the discrete state vector is:
<pre>
    State Vector
   x    y   z   t
   2    0   3   8
</pre>
The variable <code>t</code> is the age variable in the finite horizon.  Now we can represent the transition of <code>y'</code> at this particular state as follows:
<pre>
    Alpha::C          Prob(y')   trim 0 cols &rarr;     Prob(y')
     i    j     y'=  0   1   2   3             y'=0   2
    -----------------------------------------------------
    0    0          1   0   0   0                1   0
    1    0          0   0   1   0                0   1
    0    1          1   0   0   0                1   0
    1    1          0   0   1   0                0   1
</pre>
<code>y</code> takes on four different values, but given that <code>x=2</code>, only two of those values are feasible next period, 0 or 2.   The overall transition routine in <span class="n">DDP</span> is smart enough to drop the columns of all zeros, but some computation can be reduced by trimming those columns inside <code>Transit()</code>.  Thus, we can focus on the trimmed 2-column representation of the transition probability.</DD>
<P/>
<DT><code>Transit()</code> returns the vector <var>y'</var> and the matrix <var>Prob(y')</var>.  </DT>
<P/>
<DD>It does this by returning an array of two elements.  See <a href="http://www.doornik.com/ox/oxsyntax.html#ox_syntax_RefReturn">Ox doc entry for return</a>. Note that the first column of Prob(y') is simple the value <code>1-i</code>.  And the second column is simply <code>i</code>.</DD>
<P/>
<DT>Use the <var>constructor</var> to support <code>Transit</code>. </DT>
    <DD>How will <code>Transit()</code> know that <code>x=2</code> currently?   And how will it know that <code>i</code> is in the first column of <code>Alpha::C</code> not the second?  This is where the object-oriented approach to building a dynamic programming model comes in handy compared to using vectors of values to represent the state vector.  <code>Transit()</code>  will know about <code>x</code> and <code>i</code> because it will be <em>constructed</em> to know them as the following code illustrates:
    <details><summary><b>Version 1.</b> Source: niqlow/templates/DynamicPrograms/MyStateVar1.ox</summary>
    <DD><pre><object width="95%" height="350" type="text/plain" data="../../templates/DynamicPrograms/MyStateVar1.ox" border="1" ></object>
</pre></DD></details></DD>
<P/>
<DT>The constructor for <code>MyStateVar</code> requires the user to send the instance of some state variable class that corresponds to <code>x</code>. </DT>
    <DD>It will be stored in a member <code>occup</code> to <q>point</q> to the right variable.  Because an argument and a member is both called <code>occup</code> we refer to the member with that name using the <code>this.</code> operator. The constructor also asks for an instance of an action variable which corresponds to <var>i</var> and stored in <code>work</code>.  Once the members are stored in members they are available for use by any method of the class, including <code>Transit()</code>.</dd>
<P/>
<DT>State variables in a discrete DP must have a pre-specified number of values, and so it is with <code>mystate</code>.</DT>
<P/>
 <DD>How many values can it take on?  The answer is: as many as the variable <code>occup</code> can take on.  This property is always stored in the <code>N</code> member, so the constructor can get <code>mystate</code>'s value from <code>occup</code>:  <code>MyStateVar</code> inherits the number of different occupations directly from the argument <code>occup</code>.  So the new base constructor passes that value through to the base constructor called by the constructor of a class derived from StateVariable.   Since <code>NonRandom</code> is really a container it does not have its own constructor.  So <code>StateVariable()</code> is called directly.</DD>
<P/>
<DT>So if <code>mystate-&gt;Transit()</code> is called it will <q>know</q> about <var>x</var> and <var>i</var>, but how will it know about the current value they have? </DT>
<P/>
 <DD><span class="n">DDP</span> stores the current value of states added to the model in its <code>v</code> member, which was shown above.  Thus the current value of <var>x</var> equals <code>occup.v</code>. In the code for Transit the expression <code>0~occup.v</code> generates, for the state above, the row vector <code>&lt;0 2&gt;</code>.  These are the only feasible values next period, or possible values of <code>y'</code>.   So the current value of <var>x</var> is not accessed from a vector of numbers, which might be the way DP code in FORTRAN might do.  </DD> <DD>Instead it is accessed from a <em>public</em> member of a variable stored within the <code>MyStateVar</code> class.  It does not matter to <code>MyStateVar</code> whether <code>occup</code> has the label <q>x</q>.  It does not matter that <code>occup</code> happens to be first in the state vector.  It <em>does</em> matter, of course, that <code>occup</code> is indeed a state variable, and it has to know this before anything is done in the model.</DD>
<P/>
 <DD>The second expression in the <code>return</code> statement is simply Ox code to copy in <code>1-i</code> and <code>i</code>.  However, these are column vectors and they get their value from values from <code>Alpha::C</code>.  </DD>
<P/>
<DT>Which column of <code>Alpha::C</code> will <code>i</code> be in?</DT>
<P/>
  <DD>The answer is whichever column the <var>work</var> choice variable is stored in. Again, the constructor requires the argument <code>work</code> which gets copied to the member with the same name.  And <span class="n">DDP</span> puts the position of the action in the action matrix in <code>pos</code>.  So whatever column it is any instance of <code>MyStateVar</code> will know which one it is.</DD>
<P/>
<h3>How is Transit() used?</h3>
<P/>
Knowing the feasible values and their transition probabilities for a single state variable is not sufficient to solve a DP problem.  The values of this state variable combine the feasible values of all other state variables to determine the possible states next period give the current state.  If the <var>value function</var> were stored as a multidimensional array (or multi-dimensional matrix, which is not possible in Ox) then this state's possible values would simply be inserted into the right index for <var>V</var>, as in <code>V[x][y][z][a]</code>.    However, in Ox this would be inefficient, and without knowing ahead of time how many states will be added to the model it is not possible to write the code.  (There is no way in Ox or C to write something like <code>V[x]...[a]</code> to allow a dynamic number of dimensions.)</p>
<P/>
<p><span class="n">DDP</span> is designed to avoid this problem by storing <var>V</var> as a one dimensional vector regardless of the number of state variables.  The state is stored as a vector (internally), and the size of a vector can be determined dynamically.  Associated with the state vector is a vector of <var>offsets</var> or indices.  Multiply the state vector and the offsets to determine the index of the state in the V vector. Each state variable has an offset which depends on the other state variables and the number of values they take on.</p>
<P/>
<p><span class="n">DDP</span> handles the offset.  The <code>Transit()</code> function only has to return the list of feasible values and their probabilities.   Actually, <span class="n">DDP</span> keeps track of several offset vectors to index different aspects of the overall solution algorithm.</p>
<P/>
<LI  id="further">Further Considerations</LI>
<P/>
<OL class="section">
<P/>
<LI>Ensure <span class="n">DDP</span> keeps the <em>actual</em> values updated.</LI>
<P/>
When you write the code for your state variable you force the user (possibly yourself) to provide information required to code the transition for <var>y</var>.  But you are relying on <span class="n">DDP</span> to process the state variables in the model, for example by looping through all the feasible current values of <var>x</var> and <var>y</var>.  Further, DDP must know that <var>i</var> is one of the actions and include a column for it in the feasible matrix.  This is done by using methods specific to the DP class for adding elements of the model.  Namely, the DP::EndogenousStates and DP::Actions methods.  So we can now complete the code that would add a variable in the model that corresponds to <var>y</var> and which can reliably follow the transition <var>y' = ix</var>.</p>
<P/>
<dd>Code Segment showing use of <code>MyStateVar</code>.
<pre>    static decl i, x, mystate;
    x = new StateVariable("x",4);
    i = new ActionVariable("i",2);
    mystate = new MyStateVar("y",x,i);
    Actions(i);
    EndogenousStates(x,mystate);
</pre></dd>
<P/>
<li>Make the code robust</li>
<P/>
    <DT>To catch errors it is helpful to check the arguments sent to the <var>constructor</var>.  </DT>
<P/>
    <DD>Although most mistakes in passing arguments would generate errors once the code starts running, the error may not occur until much later than when <code>MyStateVar</code> is called.   Worse, since Ox is dynamically typed, and since it initializes <code>static</code> variables at 0 it is possible for incorrect information sent to the constructor to mimic valid information.</DD>
<P/>
    <DT>Even when using the variable for yourself it is useful to check the inputs.  </DT>
<P/>
    <DD>If others will build on your code then it is extremely helpful to check arguments for them to develop code quickly. The key is that the arguments must be of the right type.  The Ox function <code>isclass()</code> is very useful here, because it checks that the arguments are derived from the correct base class (or the correct intermediate class).</DD>
<P/>
    <DT>The transit code can be made a little better.  </DT>
<P/>
     <DD>In particular, for the interpretation given so far the <var>x</var> variable takes on the value 0.  This might be code for not being associated with any occupation, which is fine.  But suppose you want this variable to handle the case that a person always has an occupation.  Then <var>y=0</var> is ambiguous. It could mean the person did not work last period or they did work but in the occupation coded as 0.  The problem is that state variables always take on the values 0 to <code>N-1</code>, at least when using the <code>v</code> member.</DD>
<P/>
    <DT>You can resolve this by referring to the <code>actual</code> member of <code>occup</code>, not <code>v</code>.</DT>
<P/>
      <DD>Then, if real occupations are not coded as 0 to <code>N-1</code> but 1 to <code>N</code> (or any other set of values), the ambiguity in coding <var>ix</var> can be resolved.  A value of 0 for this state variable indicates the person did not work last period and starts out with no occupation. If there is an occupation actually coded as 0, then this state variable will infer that not working does not reset occupation.  That is, occupation is determined by something else (such as the kinds of jobs the person chooses to look for). Note that <em>by default> </em><code>actual</code> is the same as <code>v</code>, but if the state or action variable has its own Discrete::Update() method it can
       set the <code>actual</code> codes associated with the internal values <code>0&hellip;N&oline;</code>.
        <details><summary>Version 2. Source: niqlow/templates/DynamicPrograms/MyStateVar.ox</summary><pre>
        <object width="95%" height="350" type="text/plain" data="../../templates/DynamicPrograms/MyStateVar.ox" border="1" ></object>
    </pre></details></dd>
<P/>
<li>Duplicates versus Pointers</li>
    Ox does some <em>very</em> subtle things with memory.  To understand it requires some understanding of the C programming language, including unions of structures.  Quoting two parts (<a href="www.doornik.com/ox/oxsyntax.html#ox_syntax_scope">scope</a> and <a href="http://www.doornik.com/ox/oxsyntax.html#ox_syntax_RefClasses">classes</a>) of the Ox documentation</a>:
        <blockquote>Note that <b>Ox assignment of arithmetic types and string type</b> implies <em>copying</em> over the contents from the right-hand side to the left-hand side.  Ox accesses an object through a<em> reference </em>to the object which is created using the new operator. An object is removed from memory using the delete operator (<em>if there is no matching delete, the object will exist until the program terminates</em>). </blockquote></p>
<P/>
    <DT>These details are important as these lines of Ox code illustrate</DT>
        <details><summary><code>Source: niqlow/examples/classreference.ox</code></summary>
        <DD><pre><object width="95%" type="text/plain" height="250" data="../../examples/classreference.ox" border="1" ></object>
        </pre></DD></details>
        <details><summary><em>Produces</em> output <code>Source: niqlow/examples/classreference.txt</code></summary><pre>
        <object width="95%" height="200" type="text/plain" data="../../examples/classreference.output.txt" border="1" ></object>
        </pre></dd></details>
    <DD>In the first three lines <code>b=a</code> and then changing <code>b</code> does <em>not</em> change the value of <code>a</code>.  However, changing the member <code>v</code> <em>does</em> change the corresponding value of <code>a</code>. In the first three assignments, Ox <em>clones</em> the right hand side of the assignment.  But when assigning a variable that is currently an instance of a class a clone is <em>not</em> made.  Instead, a <em>reference </em>  or <em>pointer</em> to the class is made. So accessing the member of the reference is equivalent to accessing the member of the assigned class.</DD>
<P/>
<DT>Returning to our example, this means  that   <code>this.occup  = occup;</code>  does not duplicate the state variable passed as an argument.  It creates a reference to it.  </DT>
    <DD>This is both powerful and a bit dangerous.  It means that <code>MyStateVar</code> can mess up the <code>x</code> variable, which should be controlled by <span class="n">DDP</span>. But it also means that as <span class="n">DDP</span> manipulates <code>x</code> the other variable <code>mystate</code> is informed automatically, without <span class="n">DDP</span> needing to know that <code>y</code> depends on the value of <code>x</code>.</DD>
<P/>
    <DT>Also note that the <code>new</code> operator allows separate instances of <code>MyStateVar</code> to be created and passed to different variables to track.</DT>
      <DD>Because <code>occup</code> and <code>work</code> are <em>not</em> declared as <code>static</code> members, each instance has its own space for these variables.  So they can be different values not pointers to the same space.</DD>
<P/>
<li>Why matrices for actions but not states? </li>
<P/>
It has been emphasized a few times that the user's code does not need to handle state variables in vectors.  So why is it required to handle actions stored as a matrix?  Here the issue is <a href="http://www.doornik.com/ox/oxtutlan.html#ox_tutlan_opt">computational speed</a> within an interpreted language like Ox and Matlab.  Namely, nested Ox loops induce a computational overhead that nested loops in compiled languages like C and FORTRAN do not.  </p>
<P/>
<p>The innermost loop of nearly all discrete dynamic programming solution algorithms is a choice over finite options.  Requiring the user-defined <code>utility()</code> and <code>Transit()</code> methods to handle the matrix of feasible actions means this inner loop can be handled with native Ox matrix routines.  Avoiding a layer of nested loops can speed up code considerably in an interpreted language like Ox.</p>
<P/>
</OL>
<P/>
<LI  id="SB">State Blocks</LI>
    <OL class="section">
    <li>Accounting for Correlated Innovations</li>
<P/>
    <DD>If a state is not <em>autonomous</em> it is <em>coevolving</em> with at least one other state variable. State variables f and g are coevolving if for some <span class="expressions">\(f^\prime, g^\prime, \alpha \in \theta.A, \eta\)</span> and <span class="expressions">\(\theta\)</span>,
    <span class="equation">$$P( f^\prime, g^\prime | \alpha,\eta,\theta ) \neq P_f(f^\prime | \alpha,\eta,\theta)  P_g(g^\prime | \alpha,\eta,\theta).$$</span>
    The term coevolving is used rather than correlated, because it is ambiguous. Some users may interpret correlated as an unconditional property of the variables. Typically <q>|</q> is not used in these notes, but here it is used to emphasize that f and g may be correlated if we do not observe or condition on current action and state values.</DD>
<P/>
    <DT>Example of state block</DT>
    <DD><details><summary>Height and weight of a child as they grow older within a model of the parent's actions.</summary>
        <DD>The child's age is a simple counter that is not only autonomous of all other states but it is also deterministic.  That is, its innovation (age\prime-age = 1) depends on nothing else in the model.</DD>
        <DD>If the model tracks the child's weight (w) then it would obviously not be deterministic.  Its transition may depend on age and actions such as meals cooked, activities paid for, etc.  However, it might be reasonable to treat weight accumulation, w\prime-w, as distributed independently of other state variables' innovations.</DD>
        <DD>However, suppose the model includes not just weight but height (h) as well.  It might be reasonable to treat h as evolving in some way separate from decisions or other factors other than age and current height (if growth of the children in the sample are not nutritionally constrained).  But obviously weight gain is correlated with height gain.</DD>
        <DD>That is, <code>MyModel</code> might specify individual transitions of the form <span class="expressions">\(P_h(h\prime|h,age) P_w(w\prime|h\prime-h,w,age)\)</span>.   This formulation could be used to rule out, for example, a growth spurt (<span class="expressions">\(h' > h\)</span>) and significant weight loss (<span class="expressions">\(w' \lt w\)</span>).   This requires a sequence in the realizations:  h&prime; is realized first and then its value feeds into the transition probabilities for weight.  In some ways this sequencing of the realizations makes the model simpler to specify.</DD>
        <DD>However, <span class="n">DDP</span> has no mechanism to ensure this sequencing occurs properly for <em>autonomous</em> variables.  That is, since h&prime; enters the transition of another variable it cannot be classified as autonomous even though its own innovation can be generated without reference to other innovations.</DD>
        <DD>To account for this correlation, the variables w and h must be specified as Coevolving and placed in a StateBlock which will determine their joint transition.  The block might, for example, ensure that weight does not go down if height goes up.  In effect, placing them in a state block specifies a transition of the form <span class="expressions">\(P_{w,h}\bigl(\,w^{\,\prime},h^{\,\prime}\,|\,h,w,age\,\bigr)\)</span>, which includes as a special case that h&prime;-h affects the transition probabilities for weight.</DD>
        <DD> Alerted to the presence of a state block in the state vector, <span class="n">DDP</span> processes the block's transition once to build up h&prime; and w&prime; simultaneously.</DD>
        </details></DD>
<P/>
<DT>Coevolving state variables must be placed in a StateBlock
    <DD>A state block is a type (derived class) of state variable.  But it has additional data and methods to account for state variables that are not autonomous with respect to each other. State blocks are autonomous with other variables and blocks.  In the example, the state variables for weight and height would be placed in a state block.   The block would handle the correlation in the innovations.  There is no method to allow nested blocks.  Only Coevolving states can be added to a block and a StateBlock is not derived from the Coevolving class.</DD>
<P/>
    <DD>Just like a single autonomous state variable, a state block can be an element of any of the state vectors, <span class="expressions">\(\epsilon\)</span>, <span class="expressions">\(\eta\)</span>, <span class="expressions">\(\theta\)</span> and <span class="expressions">\(\gamma\)</span>. For example, serially uncorrelated but contemporaneously correlated wage offers would be handled as an exogenous state block.  If accepted wages do not enter the state next period then the block could be fully exogenous.  Otherwise it would be placed in the semi-exogenous class. </DD>
<P/>
    <DD>Note that the Clock is a State Block, so its transitions cannot depend on states outside the block.  The user can derive their own class of Clock that includes coevolving states. State variables added to the clock must be (derived from) TimeVariable objects, which is a 'container' class derived from coevolving.</DD>
<P/>
<DT>The worst case</DT>
    <DD>The setup can handle a general transition. The worst case is that all innovations are correlated and the endogenous vector would consist of a single state block containing all the state variables.  Thus a user of <span class="n">DDP</span> can code a completely general multivariate process.  </DD>
<P/>
    <DD>This 'black box' state must be derived from Clock if it is to handle everything. The advantage of allowing for autonomous state variables, rather than making everything a state block, is the ability to define standard kinds of variables that can be mixed and matched in different models with little to no programming required.</DD>
<P/>
<LI id="CSB">How to Create a State Block</LI>
<P/>
These instructions follow the ones provided for creating a <a href="#ASV">StateVariable</a>.  They are simpler and more to the point, focussing on the distinct features of state blocks.  Most of the additional considerations apply here as well but are not discussed again.</p>
<P/>
<OL class="steps">Steps
    <LI>Duplicate the State Block Template File</LI>
        <DT>Pick a name for your new kind of StateBlock.</DT>
    <DD>It cannot have spaces or symbols except <em>_</em>. These instructions will refer to <code>&laquo;BlockName&raquo;</code> for whatever name you chose.</DD>
<P/>
    <DT>Copy <code>niqlow/templates/DynamicPrograms/StateBlock.ox</code> to a file called <code>&laquo;BlockName&raquo;.ox</code>.</DT>
    <dd class="example"><details><summary>Contents of <code>Source: niqlow/templates/DynamicPrograms/StateBlock.ox</code></summary>
<pre><object width="100%" height="300" type="text/plain" data="../../templates/DynamicPrograms/StateBlock.ox" border="1" ></object>
</pre></details></dd>
<P/>
    <DT>Decide how you want to include your code: see <a href="StateVariable.ox.html#incorimp">include or import</a>.</DT>
<P/>
<LI>Choose a <em>base class</em> to derive your block from.</LI>
<P/>
    There are fewer predefined blocks than autonomous variables.  So it is likely that <code>StateBlock</code> will be the base for your class.</p>
<P/>
<LI>Declare needed elements (members and methods). </LI>
     <DT>Besides other information needed to compute the transition (see the StateVariable instructions), the state variables to be tracked in the block should be declared as data.</DT>
    <DD> For example,<pre>
        struct Vitals : StateBlock {
            decl wght, hght;
            Vitals();
            Transit();
            Update();
            GrowthProbs();
            }
</pre></dd>
<P/>
    <DT>As with StateVariable there is one required and two <q>optional</w> methods that must be provided for each new state variable.</DT>
      <DD>The required method is the <em>constructor</em> for the state variable. The optional methods are called <code>Transit()</code> and <code>Update()</code> that compute the transition and update the <em>actual</em> discrete values associated with the state variable.</DD>
<P/>
    <DT>We have listed another method <code>GrowthProb()</code>, which will be presumed to return a vector of transition
        probabilities in a format described below.</DT>
<P/>
<LI>Code the constructor method</LI>
        <DT>In DDP your block has to call the constructor of the base class, define the component variables and add them to the block using StateBlock::AddToBlock().</DT>
        <DD>The state variables could exist outside the block but they should <em>not</em> be added to the DP model separately.<pre>
        Vitals::Vitals() {
            StateBlock("vitals");
            wght = new Coevolving("w",10);
            hght = new Coevolving("h",6);
            AddToBlock(wght,hght);
            }
</pre></dd>
    <DT>It would be very bad practice to hard code the constants 10 and 6 in the definition of the class.</DT>
        <DD>Those kinds of dimensions should be decided by the user who includes the block in their model.  It is done in the example to abstract away from passing information to the constructor since this is the same as with a StateVariable.</DD>
<P/>
<LI>Code the <code>Transit()</code> method</LI>
    The major difference between a StateVariable and a StateBlock:  a state variable <code>Transit()</code> function returns a single row vector of "prime states" but a block must return a matrix of feasible "prime" states, each row is the state of the corresponding member of the block in the order they were added to the block.  The transition probabilities still pertain to each column of the matrix.  The rows of the transition probabilities correspond to the rows of the feasible actions <span class="expressions">\(\theta\)</span>.A.</p>
<P/>
   <DT><code>Transit</code> can access the feasible actions <code><span class="expressions">\(\alpha\)</span></code> at the <em>current</em> state. in <a href="DDPShared.ox.html#Alpha___C">C</a>.</DT>
<P/>
   <DT>Your code has to return two items, sent back in an Ox <em>array</em>. </DT>
        <DD>The first is a <em>matrix vector</em> of feasible values, <code>F</code>: the values this block could take on next period.  Each row corresponds to one of the variables in the block.  Each column is a different outcome.  This is what allows for correlated transitions within a block. The other output is a <em>matrix</em> of transition probabilities, <code>P</code>.   The rows of the matrix must match the <em>rows</em> of <code>Alpha::C</code>; the columns must match the columns of the row vector <code>F</code>.  The <var>ij</var> element of <code>P</code> is the probability that your state block takes on the vector of values in column j of <code>F</code> given the agent chooses the ith action in the feasible set <code>Alpha::C</code>.</DD>
<P/>
    <DT>As a simple example: </DT>
     <DD>Suppose that height increases by one value or stays the same.  Weight can go up or down or stay the same.  However, weight cannot go down if height goes up (the correlated innovation).  Further, assume that the transitions do not depend on actions.  In this case, the probabilities are duplicated using <code>reshape</code> to get the right dimensions:
    <pre>
        Vitals::Transit() {
            decl F, P;
            F =   wght.v-1 ~ wght.v ~ wght.v+1 ~ wght.v   ~ wght.v+1
                | hght.v   ~ hght.v ~ hght.v   ~ hght.v+1 ~ hght.v+1;
            P = GrowthProb();
            return { F , reshape(P,Alpha::N,columns(F)) };
            }
</pre>
So, if weight and height were currently at levels 2 and 3, respectively, then <code>F</code> would be:<pre>
              1 2 3 2 3
              3 3 3 4 4;
            </pre>
Notice that this transition matrix imposes the coevolving condition that weight cannot fall when height increases. There is no way to achieve this with two autonomous variables because their innovations are statistically independent.</dd>
<P/>
    <DT>This code assumes that <code>GrowthProb()</code> will return a <var>1&times;5</var> vector of probabilities, corresponding to the five possible outcomes in <code>F</code>.</DT>
<P/>
      <DD>The user would have to write that function and may have to pass parameters or other information in the constructor function.  We are skipping those issues because they are discussed in the <a href="StateVariable.ox.html">State Variable</a> case.  Then <code>reshape()</code> simply duplicates row-by-row since weight and height change do not depend on current actions.</DD>
<P/>
   <DT>Also, note that the code above is too simple to work properly.</DT>
<P/>
     <DD>It ignores the fact that there minimum and maximum values of the discrete states: <code>wght.v-1</code> or <code>hght.v+1</code> will be incorrect when the current values are near the bounds and this will eventually cause an error. The formula for <code>F</code> works fine as long as both variables are away from their boundaries and it illustrates the key issue here of what a block transition looks like.</DD>
<P/>
    <DT>The user has the option to provide a <code>Update()</code> function for the block.  </DT>
<P/>
    <DD>This should update a matrix of actual values that correspond to the <code>.v</code> values of each variable. If there are M variables in the block, each taking on <code>a<sub>m</sub>.N</code> values, then the actual matrix will be <code>N &times;(&prod;<sub>m</sub>&nbsp; a<sub>m</sub>.N)</code>.</DD>
<P/>
    <LI>Add the block to the DP model:</LI>
    <dd class="example"><pre>
        decl stats;
        &vellip;
<P/>
        SemiExogenousStates(stats = new Vitals());
        </pre>
      In this case, the vital state process is exogenous to other state variables, but if it influences the transitions of other state variables then the block is only <em>semi-exogenous</em>.</dd>
   </OL>
<P/>
<LI  id="ASB">Accessing  State Block Values </LI>
<P/>
Since a StateBlock is a type of StateVariable it has a <code>.v</code> data member.  <span class="n">DDP</span> ensures that it always contains the vector of values of the state variables, in the same order as they were sent to AddToBlock.  And this means that CV() will return the vector of values for a block just as it returns <code>.v</code> for a scalar state. In addition, AV() will return the vector of <code>actual</code> values that correspond to the indices in <code>.v</code>.  That is, it will pull out of the <code>actual</code> matrix the right value for each of the M variables at their current values.</p>
<P/>
</OL>
<P/>
<li id="Trans">The Transition for states and state vectors</li>
<P/>
<DT>Terminology</DT>
    <DD>Recall that generic elements of the vectors are denoted with corresponding Roman letters (h<sub>2</sub> is an element of <span class="expressions">\(\eta\)</span>).  <span class="n">DDP</span> keeps track of the individual state variables inside the block as well the block itself.  So elements of a block can still be denoted generically. The difference is that the block handles the transition of all the members of the block. So in defining the transition of the state vectors, the generic elements are either autonomous state variables or a state block. But from the point of view of <code>MyModel</code> each generic element is a separate state variable.</DD>
<P/>
<DT>The overall state transition is the product of the separate vector transitions:</DT>
<P/>
<span class="equation">$$P(\zeta^{\,\prime},\epsilon^{\,\prime},\eta^{\,\prime},\theta^{\,\prime},\gamma^{\,\prime}\ |\ \alpha,\zeta,\epsilon,\eta,\theta,\gamma\ ) = f_\zeta(\zeta^{\,\prime}) \times P_\epsilon(\epsilon^{\,\prime}) \times P_\eta(\eta^{\,\prime}) \times P_\theta(\theta^{\,\prime}\ |\ \alpha,\eta,\theta) \times I\left\{\gamma^{\,\prime}=\gamma\right\}.$$</span>
<P/>
    <DD>The restricted natures of the different vectors is displayed by excluding them from other transitions.  In particular, both <span class="expressions">\(\zeta\)</span> and <span class="expressions">\(\epsilon\)</span> are excluded from all other transitions. The continuity of the <span class="expressions">\(\zeta\)</span>'s distribution is illustrated by using <span class="expressions">\(f_\zeta()\)</span> instead of <span class="expressions">\(P()\)</span> for its transition.  The semi-exogenous nature of <span class="expressions">\(\eta\)</span> is show by its own IID transition and the fact that it is not excluded from the transition of <span class="expressions">\(\theta\)</span>.  The current value of <span class="expressions">\(\eta\)</span> can have a direct effect on the transition of endogenous states but its own transition depends on nothing.  Finally, on the other side of the full endogenous states <span class="expressions">\(\theta\)</span> is the transition of the grouping vector <span class="expressions">\(\gamma\)</span>.  Since it is fixed during a given program its transition is an indicator for keeping the same value next period.  The realized values of all the state variables do affect the transition of <span class="expressions">\(\theta^{\,\prime}\)</span> but, except for <span class="expressions">\(\theta\)</span> and <span class="expressions">\(\eta\)</span>, only indirectly through the agent's optimal choice of <span class="expressions">\(\alpha\)</span> conditional on the full realized state.  We could illustrate this above by writing <span class="expressions">\(\alpha;\)</span> as <span class="expressions">\(\alpha(\zeta,\epsilon,\eta,\theta,\gamma)\)</span>. </dd>
<P/>
<DT>In turn, each state vector's transition is the product of the individual elements (either block or autonomous):</DT>
<P/>
<span class="equation">$$\eqalign{
P_\epsilon \left(\epsilon^{\,\prime}\right) &= \prod_{k=0,\dots,\epsilon.N-1} P_{e_k}(e_k^\prime)\cr
P_\eta \left(\eta^{\,\prime}\right) &= \prod_{k=0,\dots,\eta.N^{-}} P_{h_k} (h_k^\prime)\cr
P_\theta \left(\theta^{\,\prime}|\alpha,\eta,\theta\right) &= \prod_{k=0,\dots,\theta.N^{-}} P_q(q_k^{\,\prime} | \alpha,\eta,\theta).\cr}$$</span>
<P/>
<DT>The group variables are constant within a single solution but across solutions follow a similar distribution:</DT>
<span class="equation">$$P_\gamma (\gamma) = \prod_{k=0,\dots,\gamma.N^{-}} P_{g_k}(g_k^\prime).$$</span>
<!--<DD><pre>&Rho;<sub>&gamma;</sub>(&gamma;) = &prod;<sub>k=0&hellip;(&gamma;.N)&oline;</sub>  &Rho;<sub>g<sub>k</sub></sub>(g<sub>k</sub>&prime;).</pre></DD>-->
</OL>
<P/>
<hr>
<LI  id="Clock">The Clock: Time-Keeping StateBlock &in; &theta;.</LI>
<P/>
<OL class="chapter">
<LI>Overview</LI>
<P/>
Time is a key concept in dynamic programming.  At least the difference between now (today) and later (tomorrow) underlies Bellman's equation.  In a stationary environment that is all that matters while solving the model.  In a non-stationary world the clock takes on more values.  The primary assumption is that time progresses: <span class="expressions">\(t^{\,\prime} \ge t\)</span>.  This allows the value function to be solved backwards in time, saving storage or computation if, mistakenly the environment is assumed to be stationary.  (That is, with stationarity a fixed point in all states must be solved at once, but with non-stationarity only a subset of the state space needs to be consider at each stage as we work backwards.)</p>
<P/>
<p>So the two simple extremes are stationarity (today is followed by tomorrow which is the same as today) and normal aging: <var>t&prime; = t+1</var> until <var>t=T&oline;</var>. However, timing can be more complicated that those two cases.  One case is an agent facing a finite horizon problem and the possibility of early death.</p>
<P/>
<p>The Clock Block is a single StateBlock that is always in the endogenous vector <span class="expressions">\(\theta\)</span>, and is always the <em>rightmost</em> element of it, in the sense that all task that span the endogenous state space will loop over time in the outermost loop.</p>
<P/>
<LI>Setting the Clock </LI>
<P/>
<DT><span class="expressions">\(\theta\)</span> <em>always</em> contains a single clock block derived from Clock.</DT>
<P/>
<DT>The simplest way to set the clock is to call DP::SetClock().  </DT>
    <DD>The first argument is either one of the <a href="DDPShared.ox.html#ClockTypes">ClockTypes</a> tags for built-in clocks, or it is an object of a class derived from Clock.</DD>
    <DD>If a tag is sent, other arguments may be required by that clock type.</DD>
<P/>
<DT>The call to <code>SetClock()</code> must take place between the calls to <code>Initialize()</code> and <code>CreateSpaces()</code></DT>
<DD>Example
<pre>
Initialize(new MyModel());
SetClock(InfiniteHorizon);
CreateSpaces();
</pre>
If <code>MyModel</code> does not set the clock explicitly, then a stationary infinite horizon clock is set by DP::CreateSpaces().</DD>
<P/>
<DT>All clock blocks have the same first two variables in the block</DT>
    <DD>The first co-evolving state variable in the clock is <var>t</var>, a state variable that is weakly monotonic:</DD>
    <DD><pre>t&prime; &ge; t
    </pre>
    With anticipation (foresight), <span class="expressions">\(V(\theta)\)</span> can/should be solved backwards in <var>t</var> if time is important in the model beyond just today and tomorrow in an infinite horizon.  </DD>
<P/>
    <DD>The second co-evolving variable in the clock block, <var>t&Prime;</var>, tracks feasible values of <var>t</var> next period during model solution.</DD>
<P/>
    <DD><span class="n">DDP</span> uses t&Prime; to avoid storing the full <span class="expressions">\(V(\theta)\)</span> while iterating. The user typically does nothing with t&Prime;.</DD>
<P/>
<DT>For example:</DT>
     <DD>With a <code>RandomMortality</code> clock described below, the next time may be either <code>t+1</code> or <code>T-1</code> if death occurs.  </DD>
<P/>
    <DD>The value function for the those two times must be available while computing the value at time <code>t</code>.  However, no other time periods must be stored, so separate coding of the <code>t</code> process and <code>t&Prime;</code> process conserves memory in complex environments. Because it plays no direct role in the mathematics (as opposed to the computations), t&Prime; is never listed as a member of <span class="expressions">\(\theta\)</span>, but it will be seen in output with the value 0. In more complex environments the clock may include other state variables whose values coevolve with t and t&Prime;.</DD>
<P/>
<LI>Current time and the decision horizon</LI>
<P/>
<DT>The clock block is available as <a href="DP.ox.html#DP___counter">counter</a>, but usually <code>MyModel</code> does not need to refer to it directly.</DT>
<DT>The current value of <var>t</var>, is available to <code>MyModel</code> as <a href="DDPShared.ox.html#I___t">t</a>.  That is,</DT>
    <DD><pre>I::t &equiv; counter.t.v
</pre>
Since <code>t</code> is in the index class I <code>MyModel</code> can use the identifier <code>t</code> for its own use.</DD>
<P/>
<DT>The decision horizon, or <code>counter.t.N</code>,  also denoted <code>T</code>, is the number of values that the time variable <code>t</code> takes on. </DT>
    <DD>The horizon of the model is
<pre>
        T &equiv; t.N
        T = 1 for an infinite horizon model (T = &infin;).
</pre></DD>
<DT>Because it is crucial to the solution method, this is a property of <code>MyModel</code> stored as <a href="DDPShared.ox.html#N___T">T</a>
<DD><pre>
When T is finite,
        N::T  &equiv;  T  =  counter.t.N,
When T = &infin;,
        N::T  &equiv;  1
</pre></DD>
<DT><span class="n">DDP</span> distinguishes between a static program (finite horizon and T = </DD>N::T = 1></span>) and a stationary environment
(T=&infin; and <code>N::T=1</code>) by checking the <em>class</em> of <code>counter</code>.</DT>
<P/>
<li>Kinds of Clocks</li>
<P/>
Also see <a href="DDPShared.ox.html#ClockTypes">ClockTypes</a>
<P/>
<DT><code>InfiniteHorizon</code>: <var>t&Prime; = t = 0 = T&oline;</var>.</DT>
    <DD>In the infinite horizon case Bellman 's equation must be iterated on from initial conditions until it converges. The algorithms know when today (t=0) is being accessed, and when tomorrow (t&prime;) is being accessed. The code for <code>MyModel</code> only has to deal with today and the transitions of state variables.</DD>
<P/>
<DT><code>Ergodic</code></DT>
    <DD>The user can set the clock to be ergodic, which means that there are no absorbing or terminal states in the state space <span class="expressions">\(\Theta\)</span>.When the clock is <code>Ergodic</code> <span class="n">DDP</span> will compute the ergodic or stationary distribution across states, <span class="expressions">\(P_\infty(\theta)\)</span>.  If the user's state transitions are not themselves stationary then this calculation may fail.</DD>
<P/>
<DT><code>SubPeriods</code></DT>
    <DD>In some models a sequence of decisions is made within a single period.  The <code>SubPeriods</code> tag creates a Divided clock.</DD>
<P/>
<DT>What do subperiods mean?</DT>
    <DD>Usually each state variable only transitions between one subperiod (which differs across states). This can be handled very easily by sending a base state variable to the SubState() augmenting class.  Simply send the sub period for which this state variable transits.  For all other subperiod transitions the variable is frozen. Each action variable is usually only changeable in one subperiod.  This is handled by providing a replacement for Bellman::FeasibleActions().</DD>
<P/>
    <DD>The discount factor <span class="expressions">\(\delta\)</span> is set to 1.0 for <var>s &lt; S-1</var>.  That is all payoffs within a subperiod occur simultaneously. The discount factor takes on it normal value for <var>s= S-1</var> to capture the gap between major periods.</DD>
<P/>
<DT>Some implications</DT>
    <DD>Because transitions all depend on the value of the subperiod <code>s</code>, all state variables must be endogenous (added to <span class="expressions">\(\theta\)</span>).  This is checked in DP::CreateSpaces. The user should <em>augment</em> state variables using </DD>
<P/>
<DT><code>NormalAging</code>:  <var>t&prime; = t+1</var>, up to <var>T&oline;</var>; <var>t&Prime;=0</var>.</DT>
    <DD>With ordinary aging Bellman's equation is solved backwards starting at t=T&oline; down to 0. The auxiliary variable t&Prime; is not needed to account for deviations from normal time so it is simply 0 always. A special case is a non-dynamic environment, <code>StaticProgram</code>, with T&line;=0. </DD>
<P/>
    <DD><span class="n">DDP</span> knows that an infinite horizon model is different than a static program, because in the static case it does not iterate on V() until convergence. Since <code>StaticProgram</code> is a tag associated with the class StaticP, which is derived from the class Aging, <span class="n">DDP</span> cannot confuse this with a Stationary environment.</DD>
<P/>
<DT><code>RandomMortality</code>: the agent either ages normally or dies before the start of the next period</DT>
    <DD>Random mortality means that, for there are two possible values of t and t&Prime; next period </DD>
    <DD><span class="expressions">\((t^{\,\prime},t^{\,\prime\prime}) = (T^{-},1)\)</span>  with prob. <span class="expressions">\(\pi(\alpha,\theta)\)</span></DD>
    <DD><span class="expressions">\((t^{\,\prime},t^{\,\prime\prime}) = (t+1,0)\)</span> with prob. <span class="expressions">\(1-\pi(\alpha,\theta)\)</span></DD>
    <DD>With premature mortality Bellman's equation is solved backwards but the final period is also tracked at each t as a potential state next period.  The use of the auxiliary state variable t&Prime; now becomes important computationally.  </DD>
<P/>
    <DD>While iterating <span class="n">DDP</span> does not store the value function for all t, only the final and next.  So when indexing these values it does not use t&prime; but t&Prime;.  It ensures that as <code>t</code> is decremented the just-solved for values are placed where <code>t&Prime; = 0</code> will reach it. This means that <code>t&Prime;=0</code> is typically associated with "ordinary" time evolution while other values are perturbations such as premature death of the agent. The mortality probability <span class="expressions">\(\pi()\)</span> can constant or depend on the current state and current actions.</DD>
<P/>
<DT><code>RandomAging</code>: the agent spends a random amount of time in each age bracket</DT>
<P/>
<DT><code>UncertainLongevity</code>:</DT>
    <DD>Many papers in the literature assume normal aging or random mortality with some long but finite maximum lifetime (say, age 100).  Often the last part of the lifecycle is included with little decision making only to get reasonable continuation values for early ages.  For <span class="expressions">\(\delta\)</span> not too close to 1 the cap on ages does not affect choices much earlier.</DD>
<P/>
    <DD>Another, perhaps more elegant, approach is to treat the lifetime itself as uncertain.  <code>t=T&oline;</code> is still the case of death which is still random and occurs with probability &pi;() as above.  But now <code>t=T&oline;-1</code> is now a stationary problem and <code>t=T&oline;</code> is a terminal state.  Otherwise, once <code>t=T&oline;-1</code> today and tomorrow are the same.  <span class="n">DDP</span> iterates on the value function at <code>t=T&oline;</code> as if it were a (non-ergodic) stationary problem, continuing until convergence.  Then it will proceed backwards as with mortality. The advantage of this approach is that there is a single choice probability for this final phase (conditional on other state variables) rather than computing and storing slightly different choice probabilities as <code>t</code> approaches <code>T&oline;</code>.  </DD>
<P/>
    <DD>The Longevity clock combines a special case of a more general notion of <code>RandomAging</code> which uses  AgeBrackets for the state clock with random mortality.  But it is not a special case of either one so it is derived as a third class from NonStationary.</DD>
<P/>
<DT><code>SocialExperiment</code>:  Phased treatment and random assignment</DT>
    <DD>In this environment the agent believes they are in a stationary problem and acts accordingly.  However, they are unexpectedly placed in a temporary experimental situation in which their utility and possibly state transitions have changed.  They again act accordingly but they know that eventually they will return to the original environment, which acts as the terminal values for the experiment.  There are three possible values of t&Prime; during treatment.</DD>
<P/>
<DT><code>RegimeChange</code></DT>
    <DD>Like a <code>SocialExperiment</code> except the unexpected environment lasts forever.</DD>
<P/>
<LI>Interacting With Value Function Iteration</LI>
<P/>
    <DT>Clocks have three virtual methods associated with them which are called by <a href="Methods.ox.html#ValueIteration">ValueIteration</a> and related solution methods.</DT>
<P/>
    <DD>Clock::Vupdate() makes sure that the scratch space for the value function is updated after each iteration of Bellman's equation.  In stationary models (or stationary time periods within a non-stationary model) this method also computes the norm of the difference between the current value functions and the last value.  This norm is checked by the solution method against the given tolerance for convergence.</DD>
<P/>
     <DD>Clock::Synch() is called any time the value of the clock changes (that is, it is called in Task::SyncStates()).  The default method simply places the current in <a href="DDPShared.ox.html#I___t">t</a> to b available to the user's code and other parts of <span class="DDP">DDP</span>. Some kinds of clocks do more than this. </DD>
<P/>
     <DD>Clock::setPstar() determines whether the next iteration should calculate choice probabilities or not.  If only one iteration is required to compute the value function at this point in the clock (no fixed point problem), then the clock will return <code>TRUE</code>.   This does not itself check for convergence, and other considerations may set <a href="DDPShared.ox.html#Flags___setPstar">setPstar</a> to TRUE.</DD>
<P/>
    <DT>Typically the user does nothing with these methods unless they are creating their own solution method.  And if the create their own clock type they may have to provide replacement methods if the inherited ones are not correct.</DT>
<P/>
</OL>
<P/>
<hr>
<P/>
<LI  id="Fixed">Time Invariants</LI>
<P/>
<OL class="chapter">
<P/>
Time invariants index different DP models (elements of <span class="expressions">\(\gamma\)</span>). Time invariants are variables that take on different values across agents but are fixed for a given agent.
<P/>
<LI>Overview</LI>
<P/>
 The basic DP model concerns a single agent in a single environment.  However, many applications involve related DP problems that differ in parameter values, which in turn alter the primitives <span class="expressions">\(U()\)</span>, <span class="expressions">\(P()\)</span>, <span class="expressions">\(\delta\)</span>. The state vector <span class="expressions">\(\gamma\)</span> holds variables that are fixed for an agent but differ across agents.  </p>
<P/>
 <p>As with other state vectors, anything that can go in <span class="expressions">\(\gamma\)</span> could be placed in <span class="expressions">\(\theta\)</span>.  However, since the state does not vary it is inefficient to included invariant states in <span class="expressions">\(\Theta\)</span>.</p>
<P/>
 <p>Instead, <span class="n">DDP</span> resuses <span class="expressions">\(\Theta\)</span> for each value of <span class="expressions">\(\gamma\)</span> and stores only a minimum amount of information for previously solved models. Only state variables derived from the TimeInvariant class can be added to <span class="expressions">\(\gamma\)</span> Invariants do not have a transition.</p>
<P/>
<LI>Fixed and Random Effects</LI>
<P/>
    <span class="n">DDP</span> distinguishes between two kinds of invariants.  Each is either a FixedEffect or a RandomEffect.  This distinction plays the same role as in panel models.  Fixed effects typically correspond to constant observed variables, such as gender.  So if the model is to be solved separately for men and women, with different primitives, then a binary FixedEffect would be added to <span class="expressions">\(\gamma\)</span>.  </p>
<P/>
    <p>On the other hand, a RandomEffect is designed to account for unobserved variation in the underlying problem.  An example would be a model that allows agents to have different (unobserved and permanent) skill levels.  A single skill variable taking on discrete values could be added to <span class="expressions">\(\gamma\)</span>  In estimation DDP will sum over the distribution of skills.</p>
<P/>
    <p>If a TimeInvariant class has a <code>Transit()</code> function defined it is never called because the DP problem presumes the value will never change.  A fixed effect also has no distribution, but a random effect does,  RandomEffect::Distribution().   </p>
<P/>
    <p>The distribution is used to integrate out the random effect after solving for behavior conditional on each value.  The distribution can depend on the value of the fixed effects. For example, the distribution of skills can depend on gender.    This is called once for each value of the fixed effects and this updates the <a href="Shared.ox.html#Discrete___pdf">pdf</a>(), a vector of probabilities or weights place on the values of the random effect.</p>
<P/>
    <p>Correlated random effects are created by adding a RandomEffectBlock to <span class="expressions">\(\gamma\)</span></p>
<P/>
<LI>The Group Space</LI>
<P/>
 Each combination of random and fixed effects implies a value of <span class="expressions">\(\gamma\)</span>, and for each <span class="expressions">\(\gamma\)</span> a <a href="DP.ox.html#Group">Group</a> node is created.  The set of all group nodes is the <em>group space</em>, denoted <span class="expressions">\(\Gamma\)</span>. </p>
<P/>
 <p>As with allowing state variables to be declared exogenous, moving time invariant variables from <span class="expressions">\(\theta\)</span> to <span class="expressions">\(\gamma\)</span> saves time and especially storage while solving the model. An invariant does not need to be tracked during iteration over <span class="expressions">\(\Theta\)</span>.  So group variable <code>Transit()</code> methods are <em>not</em> called for each iteration over <var>t</var> and <var>t&Prime;</var>.</p>
<P/>
 <p>Storage is re-used while solving for different values of <span class="expressions">\(\gamma\)</span>. <span class="n">DDP</span> reuses the state space <span class="expressions">\(\Theta\)</span> for each value of <span class="expressions">\(\gamma\)</span>. Choice probabilities <span class="expressions">\(P^\star(\alpha | \epsilon, \eta, \theta, \gamma )\)</span> are stored separably for each random value of <span class="expressions">\(\gamma\)</span>.  <span class="expressions">\(EV(\theta)\)</span> integrates out the random effects, conditional on the value of the fixed effects in <span class="expressions">\(\gamma\)</span>. Both utility and a transitions can depend on the value of fixed effects.  However, only utility can depend on random effects.</p>
<P/>
<DT>Finite Mixture Heterogeneity</DT>
    <DD><span span="n">FiveO</span> includes options for finite-mixture objectives.  This can be used seamlessly to estimate parameters of a DDP that vary across groups.</DD>
<P/>
</OL>
<P/>
<li  id="Auxiliary">Auxiliary Values</li>
<P/>
An auxiliary value <span class="expressions">\(x\)</span> is typically a function of the state and action vectors that would be observed in the data or is of interest in itself.  It is based on a class derived from AuxiliaryValue and is added to the list <span class="expressions">\(\chi\)</span>.</p>
<P/>
Elements of <span class="expressions">\(\chi\)</span> are user-defined  <em>auxiliary variables</em>, sometimes referred to as <q>payoff-relevant</q> variables in the DP literature.  Auxiliary variables are functions of current states and actions (and not functions of past or future outcomes), so <span class="expressions">\(\chi\)</span> adds no additional information to the full outcome. That is, <span class="expressions">\(\chi\)</span> is redundant within Y*, whereas the other actions and states each contain information.  Auxiliary variables are involved in partial observability of the realized DP.</p>
<P/>
<p>Auxiliary values are added to the outcome (appended to <span class="expressions">\(\chi\)</span>) using DP::AuxiliaryOutcomes(). The value of the variable is set in the method <code>Realize()</code>, which is a replacement for virtual AuxiliaryValue::Realize().</p>
<P/>
<p><code>Realize()</code> sets the value of <code>v</code> given the current state and outcome.  This value is then added to the realization.   <code>Auxiliary</code> variables are never referenced nor realized by <span class="n">niqlow</span> while solving the DP problem, because they plays no role in the solution.  They are realized only when simulating the solved model or when matching the model to external data. The user might realize values in the process of computing utility.</p>
<P/>
<p>The user may break  up <code>Utility()</code> into functions that help determine it.  These can be <em>static</em> methods of <code>MyModel</code>.  Then some of these functions may be observed in data and might enter econometric estimation.  StaticAux is a auxiliary value class that can be used as a <q>wrapper</q> for such functions as shown below.</p>
<P/>
<p>Auxiliary values are also used to code <em>indicators</em> and <em>interaction variables</em> in data sets.  For example, if <span class="expressions">\(a\)</span> is an action to choose among 5 options the data may include four variables that are indicators for all but one of the options being observed, <span class="expressions">\(y_k = I\{a=k\}\)</span>.  Instead of having to create a set of binary action variables to match this data the user can create a set of Indicators, each of which is an auxiliary outcome that will match whether <span class="expressions">\(a=k\)</span> or not (as well as the probability of that occurring in a prediction data set).The DP::Indicators() method can be used to generate all four indicators at once.  DP::Interactions and  DP::MultiInteractions between discrete actions and states can be created as can interactions between a auxiliary variable and a discrete quantity.</p>
<P/>
<li id="Continuous">Conditional Continuous Choices <mark>NEW and experimental</mark></li></a>
<P/>
A model may have a utility of the form:
<span class="equation">$$U(\alpha,\theta) = u(x^\star;\alpha,\theta)$$</span>
where <span class="equation">$$x^\star = \arg\max_{x} c(x;\alpha,\theta).$$</span>
That is, the agent makes a continuous choice over <span class="expressions">\(x\)</span> conditional on the state and the discrete action <span class="expressions">\(\alpha\)</span>.  This conditional continuous choice (<pre>CondContChoice</pre>) then determines the indirect utility of the discrete actions.  One special case would that <span class="expressions">\(u() = c(x^\star;\alpha,\theta)\)</span>: that is, the utility is simply the indirect utility over the continuous choice.   (ASnother possibility is that <span class="expressions">\(x^\star\)</span> directly affects the transition as in <span class="expressions">\(P(\theta^{\,\prime};x^\star,\alpha,\theta)\)</span>.  <mark>Currently this is not supported. The user may be able to use the features below to help implement this.</mark></p>
<P/>
A continuous choice is related to <code>AuxiliaryValues</code>, in the sense that you may match <span class="expressions">\(x^\star\)</span> to observed data.   If the continuous choice has a closed form then it can be represented as a static function and included in observations using the StaticAux wrapper.  If the optimal choice requires sequential optimization then the <a href="..\fiveO\Objective.html#CondContChoice">CondContChoice</a> objectitve can be used to carry this out efficiently.  This allows for a single objective to represent each conditional choice and to minimize the amount of additional storage required.
<P/>
<DD><pre>
    struct Cost : CondContChoice {
        vfunc();
        }
    Cost::Cost(x) {
        CondContChoice("mC",x);
        }
    Cost::vfunc() {
        v = -exp( x );
        }
<P/>
    struct MyModel : Bellman {
        decl xvals;
<P/>
        }
    MyModel::MyModel() {
<P/>
        }
    mCost = new CondContChoice("mC",x);
    x = new Positive("x",2.0);
    mCost = new CondContChoice("mC",x);
    mCost -> Algor( new BFGS(mCost) );
</pre></DD>
<P/>
<li  id="#Volume">Volume (getting output specific to a variable)</li>
    <DT>All <a href="Shared.ox.html#Quantity">Quantity</a> based objects have their own <code>Volume</code> member.</DT>
        <DD>By default the Volume is set to <code>SILENT</code>.</DD>
<P/>
    <DT>If you set the volume to one of the other <a href="Shared.ox.html#NoiseLevels">NoiseLevels</a> then:</DT>
        <DD>Some internal routines will print out information specific to variable. The output goes to the <code>Variables</code> log file.</DD>
<P/>
</OL>

<dl><dt class="author">Author:</dt><dd class="author">&copy; 2011-2021 <a href="https://ferrall.github.io/">Christopher Ferrall</a> </dd>

<a id="auto"><hr><h1>Documentation of  Items Defined in Variables.ox <a href="#"><span class="skip"><abbr title=" Back to top">&nbsp;&#8679;&nbsp;</abbr></span></a></h1></a></dd>
</dl>
<a name="ActionVariable"></a>
<h2><span class="icon"><img class="icon" src="icons/class.png">&nbsp;</span><span class="text">ActionVariable : <a href="Shared.ox.html#Discrete">Discrete</a> : <a href="Shared.ox.html#Quantity">Quantity</a></span></h2>

An element of the action vector <span class="expressions">\(\alpha\)</span>.

<dl><dt class="example">Example:</dt><dd class="example"><pre>MyModel : DPparent {
    static decl a;
    &vellip;
    }
&vellip;
MyModel::Initialize() {
    DPparent::Initialize(new MyModel());
    &vellip;
    a = new ActionVariable("choice",2);
    Actions(a);
    &vellip;
    CreateSpaces();
    }</pre>
</dd>
</dd>
</dl>
<table class="method_table">
<tr><td colspan="3" class="header" valign="top">Public fields</td></tr><tr class="even">
<td class="declaration"><img class="icon" src="icons/field_s.png">&nbsp;<a href="Variables.ox.html#ActionVariable___vL">vL</a></td>
<td class="modifiers"></td>
<td class="description">vector of value labels.</td>
</tr>
<tr><td colspan="3" class="header" valign="top">Public methods</td></tr><tr class="even">
<td class="declaration"><img class="icon" src="icons/method_s.png">&nbsp;<a href="Variables.ox.html#ActionVariable___ActionVariable">ActionVariable</a></td>
<td class="modifiers"></td>
<td class="description"></td>
</tr>
<tr class="odd">
<td class="declaration"><img class="icon" src="icons/method_s.png">&nbsp;<a href="Variables.ox.html#ActionVariable___myAV">myAV</a></td>
<td class="modifiers">virtual</td>
<td class="description"></td>
</tr>
<tr class="even">
<td class="declaration"><img class="icon" src="icons/method_s.png">&nbsp;<a href="Variables.ox.html#ActionVariable___myCV">myCV</a></td>
<td class="modifiers">virtual</td>
<td class="description"></td>
</tr>
<tr class="odd">
<td class="declaration"><img class="icon" src="icons/method_s.png">&nbsp;<a href="Variables.ox.html#ActionVariable___myEV">myEV</a></td>
<td class="modifiers"></td>
<td class="description"></td>
</tr>
</table>

<dl class="inherited">
<dt>Inherited methods from <a href="Shared.ox.html#Discrete">Discrete</a>:</dt><dd><a href="Shared.ox.html#Discrete___Discrete">Discrete</a>, <a href="Shared.ox.html#Discrete___PDF">PDF</a>, <a href="Shared.ox.html#Discrete___SetActual">SetActual</a>, <a href="Shared.ox.html#Discrete___Track">Track</a>, <a href="Shared.ox.html#Discrete___Update">Update</a></dd>
<dt>Inherited methods from <a href="Shared.ox.html#Quantity">Quantity</a>:</dt><dd><a href="Shared.ox.html#Quantity___SetVolume">SetVolume</a></dd>
</dl>

<dl class="inherited">
<dt>Inherited fields from <a href="Shared.ox.html#Discrete">Discrete</a>:</dt><dd><a href="Shared.ox.html#Discrete___actual">actual</a>, <a href="Shared.ox.html#Discrete___N">N</a>, <a href="Shared.ox.html#Discrete___pdf">pdf</a>, <a href="Shared.ox.html#Discrete___subv">subv</a>, <a href="Shared.ox.html#Discrete___vals">vals</a></dd>
<dt>Inherited fields from <a href="Shared.ox.html#Quantity">Quantity</a>:</dt><dd><a href="Shared.ox.html#Quantity___L">L</a>, <a href="Shared.ox.html#Quantity___logf">logf</a>, <a href="Shared.ox.html#Quantity___pos">pos</a>, <a href="Shared.ox.html#Quantity___track">track</a>, <a href="Shared.ox.html#Quantity___v">v</a>, <a href="Shared.ox.html#Quantity___Volume">Volume</a></dd>
</dl>

<a name="BinaryChoice"></a>
<h2><span class="icon"><img class="icon" src="icons/class.png">&nbsp;</span><span class="text">BinaryChoice : <a href="Variables.ox.html#ActionVariable">ActionVariable</a> : <a href="Shared.ox.html#Discrete">Discrete</a> : <a href="Shared.ox.html#Quantity">Quantity</a></span></h2>

Easy way to create a binary choice.

<dl><dt class="example">Example:</dt><dd class="example"><pre>MyModel : DPparent {
    static decl a;
    &vellip;
    }
&hellip;
MyModel::Initialize() {
    DPparent::Initialize(new MyModel());
    &vellip;
    a = new BinaryChoice();
    Actions(a);
    &vellip;
    CreateSpaces();
    }</pre>
</dd>
</dd>
</dl>
<table class="method_table">
<tr><td colspan="3" class="header" valign="top">Public methods</td></tr><tr class="even">
<td class="declaration"><img class="icon" src="icons/method_s.png">&nbsp;<a href="Variables.ox.html#BinaryChoice___BinaryChoice">BinaryChoice</a></td>
<td class="modifiers"></td>
<td class="description"></td>
</tr>
</table>

<dl class="inherited">
<dt>Inherited methods from <a href="Variables.ox.html#ActionVariable">ActionVariable</a>:</dt><dd><a href="Variables.ox.html#ActionVariable___ActionVariable">ActionVariable</a>, <a href="Variables.ox.html#ActionVariable___myAV">myAV</a>, <a href="Variables.ox.html#ActionVariable___myCV">myCV</a>, <a href="Variables.ox.html#ActionVariable___myEV">myEV</a></dd>
<dt>Inherited methods from <a href="Shared.ox.html#Discrete">Discrete</a>:</dt><dd><a href="Shared.ox.html#Discrete___Discrete">Discrete</a>, <a href="Shared.ox.html#Discrete___PDF">PDF</a>, <a href="Shared.ox.html#Discrete___SetActual">SetActual</a>, <a href="Shared.ox.html#Discrete___Track">Track</a>, <a href="Shared.ox.html#Discrete___Update">Update</a></dd>
<dt>Inherited methods from <a href="Shared.ox.html#Quantity">Quantity</a>:</dt><dd><a href="Shared.ox.html#Quantity___SetVolume">SetVolume</a></dd>
</dl>

<dl class="inherited">
<dt>Inherited fields from <a href="Variables.ox.html#ActionVariable">ActionVariable</a>:</dt><dd><a href="Variables.ox.html#ActionVariable___vL">vL</a></dd>
<dt>Inherited fields from <a href="Shared.ox.html#Discrete">Discrete</a>:</dt><dd><a href="Shared.ox.html#Discrete___actual">actual</a>, <a href="Shared.ox.html#Discrete___N">N</a>, <a href="Shared.ox.html#Discrete___pdf">pdf</a>, <a href="Shared.ox.html#Discrete___subv">subv</a>, <a href="Shared.ox.html#Discrete___vals">vals</a></dd>
<dt>Inherited fields from <a href="Shared.ox.html#Quantity">Quantity</a>:</dt><dd><a href="Shared.ox.html#Quantity___L">L</a>, <a href="Shared.ox.html#Quantity___logf">logf</a>, <a href="Shared.ox.html#Quantity___pos">pos</a>, <a href="Shared.ox.html#Quantity___track">track</a>, <a href="Shared.ox.html#Quantity___v">v</a>, <a href="Shared.ox.html#Quantity___Volume">Volume</a></dd>
</dl>

<h2><span class="icon"><img class="icon" src="icons/class.png">&nbsp;</span><span class="text">ActionVariable</span></h2>

<a name="ActionVariable___ActionVariable"></a>
<h3><span class="icon"><img class="icon" src="icons/method.png">&nbsp;</span><span class="text">ActionVariable</span></h3>

<dl><dd>

</dd></dl>

<hr>
<a name="ActionVariable___myAV"></a>
<h3><span class="icon"><img class="icon" src="icons/method.png">&nbsp;</span><span class="text">myAV</span></h3>

<dl><dd>

</dd></dl>

<hr>
<a name="ActionVariable___myCV"></a>
<h3><span class="icon"><img class="icon" src="icons/method.png">&nbsp;</span><span class="text">myCV</span></h3>

<dl><dd>

</dd></dl>

<hr>
<a name="ActionVariable___myEV"></a>
<h3><span class="icon"><img class="icon" src="icons/method.png">&nbsp;</span><span class="text">myEV</span></h3>

<dl><dd>

</dd></dl>

<hr>
<a name="ActionVariable___vL"></a>
<h3><span class="icon"><img class="icon" src="icons/field.png">&nbsp;</span><span class="text">vL</span></h3>

<span class="declaration">decl vL [public]</span>
<dl><dd>
vector of value labels.

</dd></dl>
<h2><span class="icon"><img class="icon" src="icons/class.png">&nbsp;</span><span class="text">BinaryChoice</span></h2>

<a name="BinaryChoice___BinaryChoice"></a>
<h3><span class="icon"><img class="icon" src="icons/method.png">&nbsp;</span><span class="text">BinaryChoice</span></h3>

<dl><dd>

</dd></dl>
<div class="footer">
Generated by <a href="http://oxdoc.sourceforge.net">oxdoc 1.1</a> &copy Copyright 2005-2014 by Y. Zwols<br>
Math typesetting by <a href="http://www.mathjax.org/">Mathjax</a>
</div>
