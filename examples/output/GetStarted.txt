Output of GetStarted
---------------------------
-------------------- DP Model Summary ------------------------
1. CLOCK
    0. Infinite Horizon
2. STATE VARIABLES
              |eps   |eta |theta -clock        |gamma
                p    s21      d      t     t'      r      f
       s.N     10      1      2      1      1      1      1


     Transition Categories (not counting placeholders and variables with N=1)
                 NonRandom       Random   Coevolving    Augmented       Timing    Invariant
     #Vars               1            1            0            0            0            0

3. SIZE OF SPACES

                       Number of Points
    Exogenous(Epsilon)               10
    SemiExogenous(Eta)                1
     Endogenous(Theta)                2
                 Times                1
         EV()Iterating                2
      ChoiceProb.track                2
  Random Groups(Gamma)                1
   Fixed Groups(Gamma)                1
       Total Untrimmed               20

4. ACTION VARIABLES
   Number of Distinct action vectors: 2
             a
    a.N      2


5. TRIMMING AND SUBSAMPLING OF THE ENDOGENOUS STATE SPACE (Theta)
                             N
    TotalReachable           2
         Terminal            1
     Approximated            0
    tfirsts (t=0..T)         0
                             2

6. FEASIBLE ACTION SETS
 
    [a]         A[0]     A[1]   
    -------------------------------
    (0)           X        X        
    (1)           X        -        
   #States        1        1
    -------------------------------
    Key: X = row vector is feasible. - = infeasible

** 0 0 0 1 1 
      0.00000
** 0 0 0 0 0 
      -2.3000
** 0 0 1 1 1 
      0.00000
** 0 0 1 0 0 
      -4.1939
** 0 0 0 1 1 
      0.00000
** 0 0 0 0 0 
      -5.3760
** 0 0 1 1 1 
      0.00000
** 0 0 1 0 0 
      -5.9289
** 0 0 0 1 1 
      0.00000
** 0 0 0 0 0 
      -6.1478
** 0 0 1 1 1 
      0.00000
** 0 0 1 0 0 
      -6.2259
** 0 0 0 1 1 
      0.00000
** 0 0 0 0 0 
      -6.2491
** 0 0 1 1 1 
      0.00000
** 0 0 1 0 0 
      -6.2560
** 0 0 0 1 1 
      0.00000
** 0 0 0 0 0 
      -6.2580
** 0 0 1 1 1 
      0.00000
** 0 0 1 0 0 
      -6.2586
** 0 0 0 1 1 
      0.00000
** 0 0 0 0 0 
      -6.2588
** 0 0 1 1 1 
      0.00000
** 0 0 1 0 0 
      -6.2589
** 0 0 0 1 1 
      0.00000
** 0 0 0 0 0 
      -6.2589
** 0 0 1 1 1 
      0.00000
** 0 0 1 0 0 
      -6.2589
** 0 0 0 1 1 
      0.00000
** 0 0 0 0 0 
      -6.2589

     Value of States and Choice Probabilities
     ------------------------------------------------------------------------------
    Indx   I   T   A   d   t     r     f       EV      |Choice Probabilities:         
       0   1   0   0   0   0     0     0      -6.258890 0.300000 0.700000
     ------------------------------------------------------------------------------
