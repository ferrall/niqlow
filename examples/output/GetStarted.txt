Output of GetStarted
---------------------------
-------------------- DP Model Summary ------------------------
1. CLOCK
    0. Infinite Horizon
2. STATE VARIABLES
              |eps   |eta |theta -clock        |gamma
                p    s21      d      t     t'      r      f
       s.N     10      1      2      1      1      1      1


     Transition Categories (not counting placeholders and variables with N=1)
                 NonRandom       Random   Coevolving    Augmented       Timing    Invariant
     #Vars               1            1            0            0            0            0

3. SIZE OF SPACES

                       Number of Points
    Exogenous(Epsilon)               10
    SemiExogenous(Eta)                1
     Endogenous(Theta)                2
                 Times                1
         EV()Iterating                2
      ChoiceProb.track                2
  Random Groups(Gamma)                1
   Fixed Groups(Gamma)                1
       Total Untrimmed               20

4. ACTION VARIABLES
   Number of Distinct action vectors: 2
             a
    a.N      2


5. TRIMMING AND SUBSAMPLING OF THE ENDOGENOUS STATE SPACE (Theta)
                             N
    TotalReachable           2
         Terminal            1
     Approximated            0
    tfirsts (t=0..T)         0
                             2

6. FEASIBLE ACTION SETS
 
    alpha       A[0]     A[1]   
    -------------------------------
    (0)           X        X    
    (1)           X        -    
   #States        1        1
    -------------------------------
    Key: X = row vector is feasible. - = infeasible


>>>>>>Value Iteration Starting
   Trip:1. Done:No. Visits:2. V diff=2.3. setP*:No
   Trip:2. Done:No. Visits:4. V diff=1.8939. setP*:No
   Trip:3. Done:No. Visits:6. V diff=1.18208. setP*:No
   Trip:4. Done:No. Visits:8. V diff=0.552908. setP*:No
   Trip:5. Done:No. Visits:10. V diff=0.218951. setP*:No
   Trip:6. Done:No. Visits:12. V diff=0.0780687. setP*:No
   Trip:7. Done:No. Visits:14. V diff=0.0231864. setP*:No
   Trip:8. Done:No. Visits:16. V diff=0.00688636. setP*:No
   Trip:9. Done:No. Visits:18. V diff=0.00204525. setP*:No
   Trip:10. Done:No. Visits:20. V diff=0.000607439. setP*:No
   Trip:11. Done:No. Visits:22. V diff=0.000180409. setP*:No
   Trip:12. Done:No. Visits:24. V diff=5.35816e-005. setP*:No
   Trip:13. Done:No. Visits:26. V diff=1.59137e-005. setP*:No
   Trip:14. Done:No. Visits:28. V diff=4.72638e-006. setP*:Yes
   Trip:15. Done:Yes. Visits:30. V diff=1.40373e-006. setP*:Yes

     Value of States and Choice Probabilities
     ------------------------------------------------------------------------------
    Indx   I   T   A   d   t     r     f       EV      |Choice Probabilities:
       1   1   1   1   1   0     0     0       1.000000 0.000000
       0   1   0   0   0   0     0    -6       0.300000 0.700000
     ------------------------------------------------------------------------------

>>>>>>Value Iteration Finished
